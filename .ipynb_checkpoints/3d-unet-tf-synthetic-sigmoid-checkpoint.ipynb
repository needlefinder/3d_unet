{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import nrrd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "logging.basicConfig(filename=\"logging_info_\"+strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())+\".log\",level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "\n",
    "from syntheticdata import synthetic_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_prediction(x_test, y_test, prediction, save=False):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    test_size = x_test.shape[0]\n",
    "    fig, ax = plt.subplots(test_size, 3, figsize=(12,12), sharey=True, sharex=True)\n",
    "    \n",
    "    x_test = crop_to_shape(x_test, prediction.shape)\n",
    "    y_test = crop_to_shape(y_test, prediction.shape)\n",
    "    \n",
    "    ax = np.atleast_3d(ax)\n",
    "    for i in range(test_size):\n",
    "        cax = ax[i, 0].imshow(x_test[i])\n",
    "        plt.colorbar(cax, ax=ax[i,0])\n",
    "        cax = ax[i, 1].imshow(y_test[i, ..., 1])\n",
    "        plt.colorbar(cax, ax=ax[i,1])\n",
    "        pred = prediction[i, ..., 1]\n",
    "        pred -= np.amin(pred)\n",
    "        pred /= np.amax(pred)\n",
    "        cax = ax[i, 2].imshow(pred)\n",
    "        plt.colorbar(cax, ax=ax[i,2])\n",
    "        if i==0:\n",
    "            ax[i, 0].set_title(\"x\")\n",
    "            ax[i, 1].set_title(\"y\")\n",
    "            ax[i, 2].set_title(\"pred\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(save)\n",
    "    else:\n",
    "        fig.show()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def crop_to_shape(data, shape):\n",
    "    \"\"\"\n",
    "    Crops the array to the given image shape by removing the border (expects a tensor of shape [batches, nx, ny, nz, channels].\n",
    "    :param data: the array to crop\n",
    "    :param shape: the target shape\n",
    "    \"\"\"\n",
    "    offset0 = (data.shape[1] - shape[1])//2\n",
    "    offset1 = (data.shape[2] - shape[2])//2\n",
    "    offset2 = (data.shape[3] - shape[3])//2\n",
    "    out = data[:, offset0:offset0+shape[1], offset1:offset1+shape[2], offset2:offset2+shape[3]]\n",
    "    return out\n",
    "\n",
    "\n",
    "def weight_variable(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.01, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv3d(x, W,keep_prob_):\n",
    "    conv_3d = tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='VALID')\n",
    "    return tf.nn.dropout(conv_3d, keep_prob_)\n",
    "#     return conv_3d\n",
    "\n",
    "def deconv3d(x, W, stride=1):\n",
    "    x_shape = tf.shape(x)\n",
    "#     print(x.get_shape())\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] * 2, x_shape[4] // 2])\n",
    "#     print(output_shape.get_shape())\n",
    "#     print(W.get_shape())\n",
    "    return tf.nn.conv3d_transpose(x, W, output_shape, strides=[1, stride, stride, stride, 1], padding='VALID')\n",
    "\n",
    "def max_pool(x,n):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, n, n, n, 1], strides=[1, n, n, n, 1], padding='VALID')\n",
    "\n",
    "def crop_and_concat(x1,x2):\n",
    "    x1_shape = tf.shape(x1)\n",
    "    x2_shape = tf.shape(x2)\n",
    "    # offsets for the top left corner of the crop\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2,  (x1_shape[3] - x2_shape[3]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], x2_shape[3], -1]\n",
    "    x1_crop = tf.slice(x1, offsets, size)\n",
    "    print(x1_crop.get_shape(), x2.get_shape())\n",
    "    return tf.concat(4,[x1_crop, x2])\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    evidence = tf.add(exponential_map,tf.reverse(exponential_map,[False,False,False,True]))\n",
    "    return tf.div(exponential_map,evidence, name=\"pixel_wise_softmax\")\n",
    "\n",
    "def pixel_wise_softmax_2(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    sum_exp = tf.reduce_sum(exponential_map, 4, keep_dims=True)\n",
    "    tensor_sum_exp = tf.tile(sum_exp, tf.stack([1, 1, 1, 1, tf.shape(output_map)[4]]))\n",
    "    return tf.div(exponential_map,tensor_sum_exp)\n",
    "\n",
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "#   return tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(output_map), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2, summaries=True):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    \n",
    "    :param x: input tensor, shape [?,nx,ny,nz,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Layers: {layers} FeaturesRoot: {features_root}\\\n",
    "                 ConvolutionSize: {filter_size}*{filter_size}*{filter_size}, PoolingSize: {pool_size}*{pool_size}*{pool_size}\"\\\n",
    "                 .format(layers=layers, features_root=features_root, filter_size=filter_size, pool_size=pool_size))\n",
    "    \n",
    "    in_node = x\n",
    "    batch_size = tf.shape(x)[0] \n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "    in_size = 144\n",
    "    size = in_size\n",
    "\n",
    "   \n",
    "    # down layers\n",
    "    with tf.name_scope('going_down'):\n",
    "        for layer in range(0, layers):\n",
    "            with tf.name_scope('layer_down_%d'%layer):\n",
    "                features = 2**layer*features_root\n",
    "                stddev = 1 / (filter_size**2 * features)\n",
    "                if layer == 0:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, channels, features], stddev)\n",
    "                else:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, features//2, features], stddev)\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features, features], stddev)\n",
    "                b1 = bias_variable([features])\n",
    "                b2 = bias_variable([features])\n",
    "                \n",
    "                conv1 = conv3d(in_node, w1, keep_prob)\n",
    "                tmp_h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(tmp_h_conv, w2, keep_prob)\n",
    "                dw_h_convs[layer] = tf.nn.elu(conv2 + b2)\n",
    "                \n",
    "                logging.info(\"Down Convoltion Layer: {layer} Size: {size}\".format(layer=layer,size=dw_h_convs[layer].get_shape()))\n",
    "                \n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size -= 4    \n",
    "                if layer < layers-1:\n",
    "                    pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "                    in_node = pools[layer]\n",
    "                    size /= 2    \n",
    "        \n",
    "    in_node = dw_h_convs[layers-1]\n",
    "        \n",
    "    # up layers\n",
    "    with tf.name_scope('going_up'):\n",
    "        for layer in range(layers-2, -1, -1):      ## 1 0\n",
    "            with tf.name_scope('layer_up_%d'%layer):\n",
    "                features = 2**(layer+1)*features_root\n",
    "                stddev = 1 / (filter_size**2 * features)\n",
    "\n",
    "                wd = weight_variable_devonc([pool_size, pool_size, pool_size, features//2, features], stddev)\n",
    "                bd = bias_variable([features//2])\n",
    "                h_deconv = tf.nn.elu(deconv3d(in_node, wd, pool_size) + bd)\n",
    "                h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)    \n",
    "                deconv[layer] = h_deconv_concat\n",
    "\n",
    "                w1 = weight_variable([filter_size, filter_size, filter_size, features, features//2], stddev)\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features//2, features//2], stddev)\n",
    "                b1 = bias_variable([features//2])\n",
    "                b2 = bias_variable([features//2])\n",
    "\n",
    "                conv1 = conv3d(h_deconv_concat, w1, keep_prob)\n",
    "                h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(h_conv, w2, keep_prob)\n",
    "                in_node = tf.nn.elu(conv2 + b2)\n",
    "                up_h_convs[layer] = in_node\n",
    "                \n",
    "                logging.info(\"Up Convoltion Layer: {layer} Size: {size}\".format(layer=layer,size=dw_h_convs[layer].get_shape()))\n",
    "                \n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size *= 2\n",
    "                size -= 4\n",
    "\n",
    "    # Output Map\n",
    "    with tf.name_scope('output_map'):\n",
    "        #stddev = 1 / (features_root)\n",
    "        weight = weight_variable([1, 1, 1, features_root, 1], stddev)\n",
    "        bias = bias_variable([1])\n",
    "        conv = conv3d(in_node, weight, tf.constant(1.0))\n",
    "        output_map = tf.nn.sigmoid(conv + bias)\n",
    "        up_h_convs[\"out\"] = output_map\n",
    "\n",
    "        if summaries:\n",
    "    #         for i, (c1, c2) in enumerate(convs):\n",
    "    #             tf.summary.image('summary_conv_%03d_01'%i, get_image_summary(c1))\n",
    "    #             tf.summary.image('summary_conv_%03d_02'%i, get_image_summary(c2))\n",
    "\n",
    "    #         for k in pools.keys():\n",
    "    #             tf.summary.image('summary_pool_%03d'%k, get_image_summary(pools[k]))\n",
    "\n",
    "    #         for k in deconv.keys():\n",
    "    #             tf.summary.image('summary_deconv_concat_%03d'%k, get_image_summary(deconv[k]))\n",
    "\n",
    "            for k in dw_h_convs.keys():\n",
    "                tf.summary.histogram(\"dw_convolution_%03d\"%k + '/activations', dw_h_convs[k])\n",
    "\n",
    "            for k in up_h_convs.keys():\n",
    "                tf.summary.histogram(\"up_convolution_%s\"%k + '/activations', up_h_convs[k])\n",
    "\n",
    "        variables = []\n",
    "        for w1,w2 in weights:\n",
    "            variables.append(w1)\n",
    "            variables.append(w2)\n",
    "\n",
    "        for b1,b2 in biases:\n",
    "            variables.append(b1)\n",
    "            variables.append(b2)\n",
    "        \n",
    "        print(\"Variable List: \", variables)\n",
    "        variables.append(weight)\n",
    "        variables.append(bias)\n",
    "        print(\"*\"*20)\n",
    "        print(\"Variable List: \", variables)\n",
    "        \n",
    "    return output_map, variables, int(in_size - size)\n",
    "\n",
    "\n",
    "class Unet(object):\n",
    "    \"\"\"\n",
    "    A unet implementation\n",
    "    \n",
    "    :param channels: (optional) number of channels in the input image\n",
    "    :param n_class: (optional) number of output labels\n",
    "    :param cost: (optional) name of the cost function. Default is 'cross_entropy'\n",
    "    :param cost_kwargs: (optional) kwargs passed to the cost function. See Unet._get_cost for more options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1, n_class=1, cost=\"dice_coefficient\", cost_kwargs={}, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.summaries = kwargs.get(\"summaries\", True)\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, None, None, None, channels], name='data')\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, None, None, None,  n_class], name='target')\n",
    "        self.keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "        \n",
    "        logits, self.variables, self.offset = create_conv_net(self.x, self.keep_prob, channels, n_class, **kwargs)\n",
    "        logging.info(\"Actual Output Shape: {}\".format(logits.get_shape()))\n",
    "        logging.info(\"Desired Output Shape: {}\".format(self.y.get_shape()))\n",
    "        \n",
    "        self.logits = logits\n",
    "        self.predicter = self.logits\n",
    "        self.predicter_label = tf.cast(self.predicter >= 0.5, tf.float32)\n",
    "        self.correct_pred = tf.cast(tf.equal(tf.reshape(self.predicter_label, [-1, n_class]), tf.reshape(self.y, [-1, n_class])), tf.float32)\n",
    "        self.cost = self._get_cost(self.logits, self.predicter, cost, cost_kwargs)\n",
    "        self.gradients_node = tf.gradients(self.cost, self.variables)\n",
    "        self.cross_entropy = tf.reduce_mean(cross_entropy(tf.reshape(self.y, [-1, n_class], name='cross_entro_label_reshape'),\n",
    "                                                          tf.reshape(pixel_wise_softmax_2(logits), [-1, n_class], name='px_logit_reshape')))\n",
    "        self.accuracy = tf.reduce_mean(self.correct_pred)\n",
    "        \n",
    "    def _get_cost(self, logits, predicter, cost_name, cost_kwargs):\n",
    "        \"\"\"\n",
    "        Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.\n",
    "        Optional arguments are: \n",
    "        class_weights: weights for the different classes in case of multi-class imbalance\n",
    "        regularizer: power of the L2 regularizers added to the loss function\n",
    "        \"\"\"\n",
    "        with tf.name_scope('cost_function'):\n",
    "            logging.info('*'*50)\n",
    "            logging.info('getting cost')\n",
    "            logging.info(\"Logits: {}\".format(logits.get_shape()))\n",
    "            logging.info(\"Y: {}\".format(self.y.get_shape()))\n",
    "            flat_logits = tf.reshape(logits, [-1, self.n_class], name='flat_logits_reshape')\n",
    "            flat_predicter = tf.reshape(predicter, [-1, self.n_class], name='flat_predicter_reshape')\n",
    "            flat_labels = tf.reshape(self.y, [-1, self.n_class], name='flat_labels_reshape')\n",
    "            if cost_name == \"cross_entropy\":\n",
    "                class_weights = cost_kwargs.pop(\"class_weights\", None)\n",
    "\n",
    "                if class_weights is not None:\n",
    "                    class_weights = tf.constant(np.array(class_weights, dtype=np.float32))\n",
    "\n",
    "                    weight_map = tf.multiply(flat_labels, class_weights, name='weightmap')\n",
    "                    weight_map = tf.reduce_sum(weight_map, axis=1)\n",
    "\n",
    "                    loss_map = tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, labels=flat_labels)\n",
    "                    weighted_loss = tf.multiply(loss_map, weight_map, name='weightloss')\n",
    "\n",
    "                    loss = tf.reduce_mean(weighted_loss)\n",
    "\n",
    "                else:\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, \n",
    "                                                                                  labels=flat_labels))\n",
    "            elif cost_name == \"dice_coefficient\":\n",
    "                intersection = tf.reduce_sum(flat_predicter * flat_labels)\n",
    "                union = tf.reduce_sum(flat_predicter) + tf.reduce_sum(flat_labels)\n",
    "                loss = 1 - 2 * intersection / union \n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Unknown cost function: \"%cost_name)\n",
    "\n",
    "            regularizer = cost_kwargs.pop(\"regularizer\", None)\n",
    "            if regularizer is not None:\n",
    "                regularizers = sum([tf.nn.l2_loss(variable) for variable in self.variables])\n",
    "                loss += (regularizer * regularizers)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def predict(self, model_path, x_test):\n",
    "        \"\"\"\n",
    "        Uses the model to create a prediction for the given data\n",
    "        \n",
    "        :param model_path: path to the model checkpoint to restore\n",
    "        :param x_test: Data to predict on. Shape [n, nx, ny, nz, channels]\n",
    "        :returns prediction: The unet prediction Shape [n, px, py, pz, labels] (px=nx-self.offset/2) \n",
    "        \"\"\"\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(init)\n",
    "        \n",
    "            # Restore model weights from previously saved model\n",
    "            self.restore(sess, model_path)\n",
    "            \n",
    "            y_dummy = np.empty((x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], self.n_class))\n",
    "            prediction = sess.run(self.predicter, feed_dict={self.x: x_test, self.y: y_dummy, self.keep_prob: 1.})\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def save(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Saves the current session to a checkpoint\n",
    "        \n",
    "        :param sess: current session\n",
    "        :param model_path: path to file system location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "    \n",
    "    def restore(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Restores a session from a checkpoint\n",
    "        \n",
    "        :param sess: current session instance\n",
    "        :param model_path: path to file system checkpoint location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        logging.info(\"Model restored from file: %s\" % model_path)\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Trains a unet instance\n",
    "    \n",
    "    :param net: the unet instance to train\n",
    "    :param batch_size: size of training batch\n",
    "    :param optimizer: (optional) name of the optimizer to use (momentum or adam)\n",
    "    :param opt_kwargs: (optional) kwargs passed to the learning rate (momentum opt) and to the optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_path = \"prediction\"\n",
    "    \n",
    "    def __init__(self, net, batch_size=1, optimizer=\"momentum\", opt_kwargs={}):\n",
    "        self.net = net\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.opt_kwargs = opt_kwargs\n",
    "        \n",
    "    def _get_optimizer(self, training_iters, global_step):\n",
    "        if self.optimizer == \"momentum\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.02)\n",
    "            decay_rate = self.opt_kwargs.pop(\"decay_rate\", 0.95)\n",
    "            \n",
    "            self.learning_rate_node = tf.train.exponential_decay(learning_rate=learning_rate, \n",
    "                                                        global_step=global_step, \n",
    "                                                        decay_steps=training_iters,  \n",
    "                                                        decay_rate=decay_rate, \n",
    "                                                        staircase=True)\n",
    "            \n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate_node, \n",
    "                                                   **self.opt_kwargs).minimize(self.net.cost, \n",
    "                                                                                global_step=global_step)\n",
    "        elif self.optimizer == \"adam\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.001)\n",
    "            self.learning_rate_node = tf.Variable(learning_rate)\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate_node, \n",
    "                                               **self.opt_kwargs).minimize(self.net.cost,\n",
    "                                                                     global_step=global_step)\n",
    "        \n",
    "        return optimizer\n",
    "        \n",
    "    def _initialize(self, training_iters, output_path, restore):\n",
    "        global_step = tf.Variable(0)\n",
    "        \n",
    "        self.norm_gradients_node = tf.Variable(tf.constant(0.0, shape=[len(self.net.gradients_node)]))\n",
    "        \n",
    "        if self.net.summaries:\n",
    "            tf.summary.histogram('norm_grads', self.norm_gradients_node)\n",
    "\n",
    "        tf.summary.scalar('loss', self.net.cost)\n",
    "        tf.summary.scalar('cross_entropy', self.net.cross_entropy)\n",
    "        tf.summary.scalar('accuracy', self.net.accuracy)\n",
    "\n",
    "        self.optimizer = self._get_optimizer(training_iters, global_step)\n",
    "        tf.summary.scalar('learning_rate', self.learning_rate_node)\n",
    "\n",
    "        self.summary_op = tf.summary.merge_all()        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        prediction_path = os.path.abspath(self.prediction_path)\n",
    "        output_path = os.path.abspath(output_path)\n",
    "        \n",
    "        if not restore:\n",
    "            logging.info(\"Removing '{:}'\".format(prediction_path))\n",
    "            shutil.rmtree(prediction_path, ignore_errors=True)\n",
    "            logging.info(\"Removing '{:}'\".format(output_path))\n",
    "            shutil.rmtree(output_path, ignore_errors=True)\n",
    "        \n",
    "        if not os.path.exists(prediction_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(prediction_path))\n",
    "            os.makedirs(prediction_path)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(output_path))\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        return init\n",
    "\n",
    "    def train(self, data_provider, output_path, training_array=None, validation_array=None, testing_array=None,\\\n",
    "              training_iters=10, epochs=100, dropout=0.75, display_step=1, restore=False):\n",
    "        \"\"\"\n",
    "        Lauches the training process\n",
    "        \n",
    "        :param data_provider: callable returning training and verification data\n",
    "        :param output_path: path where to store checkpoints\n",
    "        :param training_iters: number of training mini batch iteration\n",
    "        :param epochs: number of epochs\n",
    "        :param dropout: dropout probability\n",
    "        :param display_step: number of steps till outputting stats\n",
    "        :param restore: Flag if previous model should be restored \n",
    "        \"\"\"\n",
    "        save_path = os.path.join(output_path, \"model.cpkt\")\n",
    "        if epochs == 0:\n",
    "            return save_path\n",
    "        \n",
    "        init = self._initialize(training_iters, output_path, restore)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            \n",
    "            if restore:\n",
    "                ckpt = tf.train.get_checkpoint_state(output_path)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.net.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            test_x, test_y = data_provider(validation_array,\"validation\")\n",
    "            pred_shape = self.store_prediction(sess, test_x, test_y, \"_init\")\n",
    "            print(\"pred_shape: \", pred_shape)\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter(output_path, graph=sess.graph)\n",
    "            logging.info(\"Start optimization\")\n",
    "            \n",
    "            avg_gradients = None\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0\n",
    "                for step in range((epoch*training_iters), ((epoch+1)*training_iters)):\n",
    "                    batch_x, batch_y = data_provider(training_array,\"training\")   \n",
    "                    # Run optimization op (backprop)\n",
    "                    _, loss, acc, lr, gradients, prediction_labels, y = sess.run((self.optimizer, self.net.cost, self.net.accuracy, self.learning_rate_node, self.net.gradients_node, self.net.predicter_label, self.net.y), \n",
    "                                                      feed_dict={self.net.x: batch_x,\n",
    "                                                                 self.net.y: crop_to_shape(batch_y, pred_shape),\n",
    "                                                                 self.net.keep_prob: dropout})\n",
    "                    total_loss += loss                    \n",
    "                    logging.info(\"Iter {:}, Minibatch Loss= {:.4f}, Accuracy= {:.4f}, Prediction= {}, Desired= {}\".format(step, loss, acc, np.unique(prediction_labels, return_counts=True), np.unique(y, return_counts=True)))\n",
    "                                                                    #np.unique(prediction_labels[...,1],return_counts=True),\n",
    "                                                                    #np.unique(y[...,1],return_counts=True)))\n",
    "                    \n",
    "                    if avg_gradients is None:\n",
    "                        avg_gradients = [np.zeros_like(gradient) for gradient in gradients]\n",
    "                    for i in range(len(gradients)):\n",
    "                        avg_gradients[i] = (avg_gradients[i] * (1.0 - (1.0 / (step+1)))) + (gradients[i] / (step+1))\n",
    "                        \n",
    "                    norm_gradients = [np.linalg.norm(gradient) for gradient in avg_gradients]\n",
    "                    self.norm_gradients_node.assign(norm_gradients).eval()\n",
    "                                      \n",
    "                    \n",
    "                #print(\"epoch stats\")\n",
    "                self.output_epoch_stats(epoch, total_loss, training_iters, lr)\n",
    "                #print(\"store predictions\")\n",
    "                self.store_prediction(sess, test_x, test_y, \"epoch_%s\"%epoch)\n",
    "                    \n",
    "                save_path = self.net.save(sess, save_path)\n",
    "                \n",
    "            logging.info(\"Optimization Finished!\")\n",
    "            \n",
    "            return save_path\n",
    "        \n",
    "    def store_prediction(self, sess, batch_x, batch_y, name):\n",
    "        #logging.info(\"Storing prediction\")\n",
    "        prediction = sess.run(self.net.predicter, feed_dict={self.net.x: batch_x, \n",
    "                                                             self.net.y: batch_y, \n",
    "                                                             self.net.keep_prob: 1.})\n",
    "        pred_shape = prediction.shape\n",
    "        \n",
    "        loss, acc = sess.run((self.net.cost, self.net.accuracy), feed_dict={self.net.x: batch_x, \n",
    "                                                       self.net.y: crop_to_shape(batch_y, pred_shape), \n",
    "                                                       self.net.keep_prob: 1.})\n",
    "        \n",
    "        logging.info(\"Validation Accuracy= %.1f, Validation Loss= %.4f\" % (acc, loss))\n",
    "        \n",
    "        return pred_shape\n",
    "    \n",
    "    def output_epoch_stats(self, epoch, total_loss, training_iters, lr):\n",
    "        logging.info(\"Epoch {:}, Average loss: {:.4f}, Learning rate: {:.4f}\".format(epoch, (total_loss / training_iters), lr))\n",
    "\n",
    "        \n",
    "\n",
    "def get_image_summary(img, idx=0):\n",
    "    \"\"\"\n",
    "    Make an image summary for 5d tensor image with index idx\n",
    "    \"\"\"\n",
    "    \n",
    "    V = tf.slice(img, (0, 0, 0, 0, idx), (1, -1, -1, -1, 1))\n",
    "    V -= tf.reduce_min(V)\n",
    "    V /= tf.reduce_max(V)\n",
    "    V *= 255\n",
    "    \n",
    "    img_w = tf.shape(img)[1]\n",
    "    img_h = tf.shape(img)[2]\n",
    "    img_z = tf.shape(img)[3]\n",
    "    V = tf.reshape(V, tf.stack((img_w, img_h, img_z, 1)))\n",
    "    V = tf.transpose(V, (3, 0, 1, 2))\n",
    "    V = tf.reshape(V, tf.stack((-1, img_w, img_h, img_z, 1)))\n",
    "    return V\n",
    "\n",
    "def loadCases(p):\n",
    "    f = open(p)\n",
    "    res = []\n",
    "    for l in f:\n",
    "        l = l[:-1]\n",
    "        if l == \"\":\n",
    "            break\n",
    "        if l[-1] == '\\r':\n",
    "            l = l[:-1]\n",
    "        res.append(l)\n",
    "    return res\n",
    "\n",
    "class BaseDataProvider(object):\n",
    "    \"\"\"\n",
    "    Abstract base class for DataProvider implementation. Subclasses have to\n",
    "    overwrite the `_next_data` method that load the next data and label array.\n",
    "    This implementation automatically clips the data with the given min/max and\n",
    "    normalizes the values to (0,1]. To change this behavoir the `_process_data`\n",
    "    method can be overwritten. To enable some post processing such as data\n",
    "    augmentation the `_post_process` method can be overwritten.\n",
    "    \n",
    "    :param a_min: (optional) min value used for clipping\n",
    "    :param a_max: (optional) max value used for clipping\n",
    "    \"\"\"\n",
    "    \n",
    "    channels = 1\n",
    "    n_class = 1\n",
    "    \n",
    "\n",
    "    def __init__(self, a_min=None, a_max=None):\n",
    "        self.a_min = a_min if a_min is not None else -np.inf\n",
    "        self.a_max = a_max if a_min is not None else np.inf\n",
    "\n",
    "    def _load_data_and_label(self,datafile):\n",
    "        data, label = self._next_data(datafile)\n",
    "            \n",
    "        data = self._process_data(data)\n",
    "        label = self._process_labels(label)\n",
    "        \n",
    "        data, label = self._post_process(data, label)\n",
    "        \n",
    "        nx = data.shape[0]\n",
    "        ny = data.shape[1]\n",
    "        nz = data.shape[2]\n",
    "\n",
    "        return data.reshape(1, nx, ny, nz, self.channels), label.reshape(1, nx, ny, nz, self.n_class)       \n",
    "    \n",
    "    def _process_labels(self, label):\n",
    "        if self.n_class == 2:\n",
    "            nx = label.shape[0]\n",
    "            ny = label.shape[1]\n",
    "            nz = label.shape[2]\n",
    "            labels = np.zeros((nx, ny, nz, self.n_class), dtype=np.float32)\n",
    "            labels[..., 1] = label\n",
    "            labels[..., 0] = 1-label\n",
    "            return labels\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def _process_data(self, data):\n",
    "        # normalization\n",
    "        data = np.clip(np.fabs(data), self.a_min, self.a_max)\n",
    "        data -= np.amin(data)\n",
    "        data /= np.amax(data)\n",
    "        return data\n",
    "    \n",
    "    def _post_process(self, data, labels):\n",
    "        \"\"\"\n",
    "        Post processing hook that can be used for data augmentation\n",
    "        \n",
    "        :param data: the data array\n",
    "        :param labels: the label array\n",
    "        \"\"\"\n",
    "        return data, labels\n",
    "    \n",
    "    def __call__(self, array = None, datafile = \"training\"):\n",
    "        if array != None:\n",
    "            if datafile == \"training\":\n",
    "                self.trainingfile_idx += 1\n",
    "                if self.trainingfile_idx >= len(array):\n",
    "                    self.trainingfile_idx = 0\n",
    "                data = self._process_data(array[self.trainingfile_idx][0])\n",
    "                label = self._process_labels(array[self.trainingfile_idx][1])\n",
    "            elif datafile == \"validation\":\n",
    "                self.validationfile_idx += 1\n",
    "                if self.validationfile_idx >= len(array):\n",
    "                    self.validationfile_idx = 0\n",
    "                data = self._process_data(array[self.validationfile_idx][0])\n",
    "                label = self._process_labels(array[self.validationfile_idx][1])\n",
    "            elif datafile == \"testing\":\n",
    "                self.testingfile_idx += 1\n",
    "                if self.testingfile_idx >= len(array):\n",
    "                    self.testingfile_idx = 0\n",
    "                data = self._process_data(array[self.testingfile_idx][0])\n",
    "                label = self._process_labels(array[self.testingfile_idx][1])\n",
    "            else:\n",
    "                raise NameError(\"No such datafile, datafile must be training, validation or testing\")\n",
    "                \n",
    "            data, label = self._post_process(data, label)\n",
    "            nx = data.shape[0]\n",
    "            ny = data.shape[1]\n",
    "            nz = data.shape[2]\n",
    "            return data.reshape(1, nx, ny, nz, self.channels), label.reshape(1, nx, ny, nz, self.n_class)\n",
    "            \n",
    "        else:\n",
    "            if datafile == \"training\":\n",
    "                data, label = self._load_data_and_label(self.training_data_files)\n",
    "            elif datafile == \"validation\":\n",
    "                data, label = self._load_data_and_label(self.validation_data_files)\n",
    "            elif datafile == \"testing\":\n",
    "                data, label = self._load_data_and_label(self.testing_data_files)\n",
    "            else:\n",
    "                raise NameError(\"No such datafile, datafile must be training, validation or testing\")\n",
    "            return data, label\n",
    "\n",
    "\n",
    "class ImageDataProvider(BaseDataProvider):\n",
    "    \"\"\"\n",
    "    Generic data provider for images, supports gray scale and colored images.\n",
    "    Assumes that the data images and label images are stored in the same folder\n",
    "    and that the labels have a different file suffix e.g. 'train/fish_1.tif' \n",
    "    and 'train/fish_1_mask.tif'\n",
    "    Usage:\n",
    "    data_provider = ImageDataProvider(\"..fishes/train/*.tif\")\n",
    "        \n",
    "    :param search_path: a glob search pattern to find all data and label images\n",
    "    :param a_min: (optional) min value used for clipping\n",
    "    :param a_max: (optional) max value used for clipping\n",
    "    :param data_suffix: suffix pattern for the data images. Default '.tif'\n",
    "    :param mask_suffix: suffix pattern for the label images. Default '_mask.tif'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, array = False, search_path='', a_min=None, a_max=None, data_suffix=\".tif\", mask_suffix='_mask.tif'):\n",
    "        \n",
    "        super(ImageDataProvider, self).__init__(a_min, a_max)\n",
    "        self.trainingfile_idx = -1\n",
    "        self.validationfile_idx = -1\n",
    "        self.testingfile_idx = -1\n",
    "        \n",
    "        if array == True:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            self.training_data_files, self.validation_data_files, self.testing_data_files = self._find_data_files() \n",
    "            assert len(self.training_data_files) > 0, \"No training files\"\n",
    "            assert len(self.validation_data_files) > 0, \"No validation files\"\n",
    "            assert len(self.testing_data_files) > 0, \"No testing files\"\n",
    "        \n",
    "            print(\"Number of training data used: %s\" % len(self.training_data_files))\n",
    "            print(\"Number of validation data used: %s\" % len(self.validation_data_files))\n",
    "            print(\"Number of testing data used: %s\" % len(self.testing_data_files))\n",
    "        \n",
    "        self.channels = 1\n",
    "        \n",
    "        \n",
    "    def _find_data_files(self):\n",
    "        rootPath = \"~/ziyang/preprocessed_data/\"\n",
    "        dataPath = rootPath+\"LabelMaps_1.00-1.00-1.00/\"\n",
    "\n",
    "        trainingCases = loadCases(\"training.txt\")\n",
    "        validationCases = loadCases(\"validation.txt\")\n",
    "        testingCases = loadCases(\"testing.txt\")\n",
    "        \n",
    "        return [dataPath+name+'/case.nrrd' for name in trainingCases],[dataPath+name+'/case.nrrd' for name in validationCases],[dataPath+name+'/case.nrrd' for name in testingCases]\n",
    "    \n",
    "    \n",
    "    def _load_file(self, path, dtype=np.float32):\n",
    "        tile = 148  ##\n",
    "        zer = np.zeros((tile,tile,tile), dtype=dtype)\n",
    "        data = nrrd.read(path)[0].astype(dtype)\n",
    "        xmin = min(data.shape[0], tile)\n",
    "        ymin = min(data.shape[1], tile)\n",
    "        zmin = min(data.shape[2], tile)\n",
    "        zer[:xmin, :ymin, :zmin] = data[:xmin, :ymin, :zmin]\n",
    "        return zer\n",
    "        \n",
    "        \n",
    "    def _next_data(self,datafile):\n",
    "        if datafile == self.training_data_files:\n",
    "            self.trainingfile_idx += 1\n",
    "            if self.trainingfile_idx >= len(datafile):\n",
    "                self.trainingfile_idx = 0\n",
    "            image_name = datafile[self.trainingfile_idx]\n",
    "        elif datafile == self.validation_data_files:\n",
    "            self.validationfile_idx += 1\n",
    "            if self.validationfile_idx >= len(datafile):\n",
    "                self.validationfile_idx = 0\n",
    "            image_name = datafile[self.validationfile_idx]\n",
    "        elif datafile == self.testing_data_files:\n",
    "            self.testingfile_idx += 1\n",
    "            if self.testingfile_idx >= len(datafile):\n",
    "                self.testingfile_idx = 0\n",
    "            image_name = datafile[self.testingfile_idx]\n",
    "        else:\n",
    "            raise ValueError(\"Datafile Not Recognized\")\n",
    "            \n",
    "        logging.info(\"Case: {}\".format(image_name))\n",
    "        label_name = image_name.replace('case', 'labelmap')    \n",
    "        img = self._load_file(image_name, np.float32)\n",
    "        label = self._load_file(label_name, np.bool)\n",
    "    \n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?, ?, ?) (?, ?, ?, ?, 32)\n",
      "(?, ?, ?, ?, ?) (?, ?, ?, ?, 16)\n",
      "Variable List:  [<tensorflow.python.ops.variables.Variable object at 0x7f72b2a7ce48>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f3a978>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f2c390>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f2c7f0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c0b4e0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1be4898>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1afacf8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f3a7b8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1a04fd0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b19fa390>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c43da0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bc5c50>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c56cf8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bdfa20>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c6de48>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bf0c18>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1aafa20>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1cd6a58>, <tensorflow.python.ops.variables.Variable object at 0x7f72b19d8f98>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1ad37b8>]\n",
      "********************\n",
      "Variable List:  [<tensorflow.python.ops.variables.Variable object at 0x7f72b2a7ce48>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f3a978>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f2c390>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f2c7f0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c0b4e0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1be4898>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1afacf8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1f3a7b8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1a04fd0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b19fa390>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c43da0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bc5c50>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c56cf8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bdfa20>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1c6de48>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1bf0c18>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1aafa20>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1cd6a58>, <tensorflow.python.ops.variables.Variable object at 0x7f72b19d8f98>, <tensorflow.python.ops.variables.Variable object at 0x7f72b1ad37b8>, <tensorflow.python.ops.variables.Variable object at 0x7f72b2a66fd0>, <tensorflow.python.ops.variables.Variable object at 0x7f72b192dd30>]\n"
     ]
    }
   ],
   "source": [
    "net = Unet(channels=1, \n",
    "           n_class=1, \n",
    "           layers=3, \n",
    "           features_root=16, summaries=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Num_Training = 50\n",
    "Num_Validation = 5\n",
    "Num_Testing = 5\n",
    "\n",
    "training_array = []\n",
    "validation_array = []\n",
    "testing_array = []\n",
    "\n",
    "LOADPATH = \"/home/ubuntu/ziyang/preprocessed_data/LabelMaps_1.00-1.00-1.00_synthetic/numpy/\"\n",
    "for num in range(Num_Training):\n",
    "    case = np.load(LOADPATH + \"training_case{}.npy\".format(num+1))\n",
    "    labelmap = np.load(LOADPATH + \"training_labelmap{}.npy\".format(num+1))\n",
    "    training_array.append([case, labelmap])\n",
    "\n",
    "for num in range(Num_Validation):\n",
    "    case = np.load(LOADPATH + \"validation_case{}.npy\".format(num+1))\n",
    "    labelmap = np.load(LOADPATH + \"validation_labelmap{}.npy\".format(num+1))\n",
    "    validation_array.append([case, labelmap])\n",
    "    \n",
    "for num in range(Num_Testing):\n",
    "    case = np.load(LOADPATH + \"testing_case{}.npy\".format(num+1))\n",
    "    labelmap = np.load(LOADPATH + \"testing_labelmap{}.npy\".format(num+1))\n",
    "    testing_array.append([case, labelmap])    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_shape:  (1, 108, 108, 108, 1)\n"
     ]
    }
   ],
   "source": [
    "data_provider = ImageDataProvider(array=True)\n",
    "\n",
    "trainer = Trainer(net, batch_size=1, optimizer=\"adam\")\n",
    "path = trainer.train(data_provider, \n",
    "                     \"./unet_trained\",\n",
    "                     training_array = training_array,\n",
    "                     validation_array = validation_array,\n",
    "                     testing_array = None,\n",
    "                     training_iters=50, \n",
    "                     epochs=60, \n",
    "                     dropout=0.5, \n",
    "                     display_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
