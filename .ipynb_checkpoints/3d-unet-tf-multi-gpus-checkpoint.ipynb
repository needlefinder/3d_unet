{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import nrrd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def plot_prediction(x_test, y_test, prediction, save=False):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    test_size = x_test.shape[0]\n",
    "    fig, ax = plt.subplots(test_size, 3, figsize=(12,12), sharey=True, sharex=True)\n",
    "    \n",
    "    x_test = crop_to_shape(x_test, prediction.shape)\n",
    "    y_test = crop_to_shape(y_test, prediction.shape)\n",
    "    \n",
    "    ax = np.atleast_3d(ax)\n",
    "    for i in range(test_size):\n",
    "        cax = ax[i, 0].imshow(x_test[i])\n",
    "        plt.colorbar(cax, ax=ax[i,0])\n",
    "        cax = ax[i, 1].imshow(y_test[i, ..., 1])\n",
    "        plt.colorbar(cax, ax=ax[i,1])\n",
    "        pred = prediction[i, ..., 1]\n",
    "        pred -= np.amin(pred)\n",
    "        pred /= np.amax(pred)\n",
    "        cax = ax[i, 2].imshow(pred)\n",
    "        plt.colorbar(cax, ax=ax[i,2])\n",
    "        if i==0:\n",
    "            ax[i, 0].set_title(\"x\")\n",
    "            ax[i, 1].set_title(\"y\")\n",
    "            ax[i, 2].set_title(\"pred\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(save)\n",
    "    else:\n",
    "        fig.show()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def crop_to_shape(data, shape):\n",
    "    \"\"\"\n",
    "    Crops the array to the given image shape by removing the border (expects a tensor of shape [batches, nx, ny, nz, channels].\n",
    "    \n",
    "    :param data: the array to crop\n",
    "    :param shape: the target shape\n",
    "    \"\"\"\n",
    "    offset0 = (data.shape[1] - shape[1])//2\n",
    "    offset1 = (data.shape[2] - shape[2])//2\n",
    "    offset2 = (data.shape[3] - shape[3])//2\n",
    "    out = data[:, offset0:offset0+shape[1], offset1:offset1+shape[2], offset2:offset2+shape[3]]\n",
    "    return out\n",
    "\n",
    "\n",
    "def weight_variable(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv3d(x, W,keep_prob_):\n",
    "    conv_3d = tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='VALID')\n",
    "    return tf.nn.dropout(conv_3d, keep_prob_)\n",
    "#     return conv_3d\n",
    "\n",
    "def deconv3d(x, W, stride=1):\n",
    "    x_shape = tf.shape(x)\n",
    "#     print(x.get_shape())\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] * 2, x_shape[4] // 2])\n",
    "#     print(output_shape.get_shape())\n",
    "#     print(W.get_shape())\n",
    "    return tf.nn.conv3d_transpose(x, W, output_shape, strides=[1, stride, stride, stride, 1], padding='VALID')\n",
    "\n",
    "def max_pool(x,n):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, n, n, n, 1], strides=[1, n, n, n, 1], padding='VALID')\n",
    "\n",
    "def crop_and_concat(x1,x2):\n",
    "    x1_shape = tf.shape(x1)\n",
    "    x2_shape = tf.shape(x2)\n",
    "    # offsets for the top left corner of the crop\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2,  (x1_shape[3] - x2_shape[3]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], x2_shape[3], -1]\n",
    "    x1_crop = tf.slice(x1, offsets, size)\n",
    "    print(x1_crop.get_shape(), x2.get_shape())\n",
    "    return tf.concat([x1_crop, x2], 4)\n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    evidence = tf.add(exponential_map,tf.reverse(exponential_map,[False,False,False,True]))\n",
    "    return tf.div(exponential_map,evidence, name=\"pixel_wise_softmax\")\n",
    "\n",
    "def pixel_wise_softmax_2(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    sum_exp = tf.reduce_sum(exponential_map, 4, keep_dims=True)\n",
    "    tensor_sum_exp = tf.tile(sum_exp, tf.stack([1, 1, 1, 1, tf.shape(output_map)[4]]))\n",
    "    return tf.div(exponential_map,tensor_sum_exp)\n",
    "\n",
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "#     return tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(output_map), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2, summaries=True):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    \n",
    "    :param x: input tensor, shape [?,nx,ny,nz,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Layers {layers}, features {features}, filter size {filter_size}x{filter_size}, pool size: {pool_size}x{pool_size}\".format(layers=layers,\n",
    "                                                                                                           features=features_root,\n",
    "                                                                                                           filter_size=filter_size,\n",
    "                                                                                                           pool_size=pool_size))\n",
    "    # Placeholder for the input image\n",
    "    nx = tf.shape(x)[1]\n",
    "    ny = tf.shape(x)[2]\n",
    "    nz = tf.shape(x)[3]\n",
    "    x_image = tf.reshape(x, tf.stack([-1,nx,ny,nz,channels]), name='input_reshape')\n",
    "    in_node = x_image\n",
    "    batch_size = tf.shape(x_image)[0]\n",
    " \n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "    \n",
    "    in_size = 1000\n",
    "    size = in_size\n",
    "    # down layers\n",
    "    with tf.name_scope('going_down'):\n",
    "        for layer in range(0, layers):\n",
    "            with tf.name_scope('layer_down_%d'%layer):\n",
    "                features = 2**layer*features_root\n",
    "                stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "                if layer == 0:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, channels, features], stddev)\n",
    "                else:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, features//2, features], stddev)\n",
    "\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features, features], stddev)\n",
    "                b1 = bias_variable([features])\n",
    "                b2 = bias_variable([features])\n",
    "\n",
    "                conv1 = conv3d(in_node, w1, keep_prob)\n",
    "                tmp_h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(tmp_h_conv, w2, keep_prob)\n",
    "                dw_h_convs[layer] = tf.nn.elu(conv2 + b2)\n",
    "\n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size -= 4\n",
    "                if layer < layers-1:\n",
    "                    pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "                    in_node = pools[layer]\n",
    "                    size /= 2\n",
    "        \n",
    "    in_node = dw_h_convs[layers-1]\n",
    "        \n",
    "    # up layers\n",
    "    with tf.name_scope('going_up'):\n",
    "        for layer in range(layers-2, -1, -1):\n",
    "            with tf.name_scope('layer_up_%d'%layer):\n",
    "                features = 2**(layer+1)*features_root\n",
    "                stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "\n",
    "                wd = weight_variable_devonc([pool_size, pool_size, pool_size, features//2, features], stddev)\n",
    "                bd = bias_variable([features//2])\n",
    "                h_deconv = tf.nn.elu(deconv3d(in_node, wd, pool_size) + bd)\n",
    "                h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)\n",
    "                deconv[layer] = h_deconv_concat\n",
    "\n",
    "                w1 = weight_variable([filter_size, filter_size, filter_size, features, features//2], stddev)\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features//2, features//2], stddev)\n",
    "                b1 = bias_variable([features//2])\n",
    "                b2 = bias_variable([features//2])\n",
    "\n",
    "                conv1 = conv3d(h_deconv_concat, w1, keep_prob)\n",
    "                h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(h_conv, w2, keep_prob)\n",
    "                in_node = tf.nn.elu(conv2 + b2)\n",
    "                up_h_convs[layer] = in_node\n",
    "\n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size *= 2\n",
    "                size -= 4\n",
    "\n",
    "    # Output Map\n",
    "    with tf.name_scope('output_map'):\n",
    "        weight = weight_variable([1, 1, 1, features_root, n_class], stddev)\n",
    "        bias = bias_variable([n_class])\n",
    "        conv = conv3d(in_node, weight, tf.constant(1.0))\n",
    "        output_map = tf.nn.elu(conv + bias)\n",
    "        up_h_convs[\"out\"] = output_map\n",
    "\n",
    "        if summaries:\n",
    "    #         for i, (c1, c2) in enumerate(convs):\n",
    "    #             tf.summary.image('summary_conv_%03d_01'%i, get_image_summary(c1))\n",
    "    #             tf.summary.image('summary_conv_%03d_02'%i, get_image_summary(c2))\n",
    "\n",
    "    #         for k in pools.keys():\n",
    "    #             tf.summary.image('summary_pool_%03d'%k, get_image_summary(pools[k]))\n",
    "\n",
    "    #         for k in deconv.keys():\n",
    "    #             tf.summary.image('summary_deconv_concat_%03d'%k, get_image_summary(deconv[k]))\n",
    "\n",
    "            for k in dw_h_convs.keys():\n",
    "                tf.summary.histogram(\"dw_convolution_%03d\"%k + '/activations', dw_h_convs[k])\n",
    "\n",
    "            for k in up_h_convs.keys():\n",
    "                tf.summary.histogram(\"up_convolution_%s\"%k + '/activations', up_h_convs[k])\n",
    "\n",
    "        variables = []\n",
    "        for w1,w2 in weights:\n",
    "            variables.append(w1)\n",
    "            variables.append(w2)\n",
    "\n",
    "        for b1,b2 in biases:\n",
    "            variables.append(b1)\n",
    "            variables.append(b2)\n",
    "\n",
    "    \n",
    "    return output_map, variables, int(in_size - size)\n",
    "\n",
    "\n",
    "class Unet(object):\n",
    "    \"\"\"\n",
    "    A unet implementation\n",
    "    \n",
    "    :param channels: (optional) number of channels in the input image\n",
    "    :param n_class: (optional) number of output labels\n",
    "    :param cost: (optional) name of the cost function. Default is 'cross_entropy'\n",
    "    :param cost_kwargs: (optional) kwargs passed to the cost function. See Unet._get_cost for more options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1, n_class=2, cost=\"dice_coefficient\", cost_kwargs={}, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.summaries = kwargs.get(\"summaries\", True)\n",
    "        \n",
    "        self.x = tf.placeholder(\"float\", shape=[None, None, None, None, channels], name='data')\n",
    "        self.y = tf.placeholder(\"float\", shape=[None, None, None, None,  n_class], name='target')\n",
    "        self.keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "        \n",
    "        logits, self.variables, self.offset = create_conv_net(self.x, self.keep_prob, channels, n_class, **kwargs)\n",
    "        logging.info(logits.get_shape())\n",
    "        logging.info(self.y.get_shape())\n",
    "        \n",
    "        self.cost = self._get_cost(logits, cost, cost_kwargs)\n",
    "        \n",
    "        self.gradients_node = tf.gradients(self.cost, self.variables)\n",
    "         \n",
    "        self.cross_entropy = tf.reduce_mean(cross_entropy(tf.reshape(self.y, [-1, n_class], name='cross_entro_label_reshape'),\n",
    "                                                          tf.reshape(pixel_wise_softmax_2(logits), [-1, n_class], name='px_logit_reshape')))\n",
    "        \n",
    "#         self.predicter = pixel_wise_softmax_2(logits)\n",
    "        self.predicter = tf.nn.softmax(logits)\n",
    "#         self.correct_pred = tf.equal(tf.(self.predicter, 4), tf.argmax(self.y, 4))\n",
    "        self.correct_pred = tf.equal(self.predicter>0.5, self.y>0.5)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "        \n",
    "    def _get_cost(self, logits, cost_name, cost_kwargs):\n",
    "        \"\"\"\n",
    "        Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.\n",
    "        Optional arguments are: \n",
    "        class_weights: weights for the different classes in case of multi-class imbalance\n",
    "        regularizer: power of the L2 regularizers added to the loss function\n",
    "        \"\"\"\n",
    "        with tf.name_scope('cost_function'):\n",
    "            logging.info('*'*50)\n",
    "            logging.info('getting cost')\n",
    "            logging.info(logits.get_shape())\n",
    "            logging.info(self.y.get_shape())\n",
    "            flat_logits = tf.reshape(logits, [-1, self.n_class], name='flat_logits_reshape')\n",
    "            flat_labels = tf.reshape(self.y, [-1, self.n_class], name='flat_labels_reshape')\n",
    "            if cost_name == \"cross_entropy\":\n",
    "                class_weights = cost_kwargs.pop(\"class_weights\", None)\n",
    "\n",
    "                if class_weights is not None:\n",
    "                    class_weights = tf.constant(np.array(class_weights, dtype=np.float32))\n",
    "\n",
    "                    weight_map = tf.multiply(flat_labels, class_weights, name='weightmap')\n",
    "                    weight_map = tf.reduce_sum(weight_map, axis=1)\n",
    "\n",
    "                    loss_map = tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, labels=flat_labels)\n",
    "                    weighted_loss = tf.multiply(loss_map, weight_map, name='weightloss')\n",
    "\n",
    "                    loss = tf.reduce_mean(weighted_loss)\n",
    "\n",
    "                else:\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, \n",
    "                                                                                  labels=flat_labels))\n",
    "            elif cost_name == \"dice_coefficient\":\n",
    "                intersection = tf.reduce_sum(flat_logits * flat_labels, axis=1, keep_dims=True)\n",
    "                mulLogits = tf.multiply(flat_logits, flat_logits, name='dicecoeff_logits_mul')\n",
    "                mulLabels = tf.multiply(flat_labels, flat_labels, name='dicecoeff_labels_mul')\n",
    "                union = tf.reduce_sum(mulLogits, axis=1, keep_dims=True) + tf.reduce_sum(mulLabels, axis=1, keep_dims=True)\n",
    "                loss = 1 - tf.reduce_mean(2 * intersection/ (union))\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Unknown cost function: \"%cost_name)\n",
    "\n",
    "            regularizer = cost_kwargs.pop(\"regularizer\", None)\n",
    "            if regularizer is not None:\n",
    "                regularizers = sum([tf.nn.l2_loss(variable) for variable in self.variables])\n",
    "                loss += (regularizer * regularizers)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def predict(self, model_path, x_test):\n",
    "        \"\"\"\n",
    "        Uses the model to create a prediction for the given data\n",
    "        \n",
    "        :param model_path: path to the model checkpoint to restore\n",
    "        :param x_test: Data to predict on. Shape [n, nx, ny, nz, channels]\n",
    "        :returns prediction: The unet prediction Shape [n, px, py, pz, labels] (px=nx-self.offset/2) \n",
    "        \"\"\"\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(init)\n",
    "        \n",
    "            # Restore model weights from previously saved model\n",
    "            self.restore(sess, model_path)\n",
    "            \n",
    "            y_dummy = np.empty((x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], self.n_class))\n",
    "            prediction = sess.run(self.predicter, feed_dict={self.x: x_test, self.y: y_dummy, self.keep_prob: 1.})\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def save(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Saves the current session to a checkpoint\n",
    "        \n",
    "        :param sess: current session\n",
    "        :param model_path: path to file system location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "    \n",
    "    def restore(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Restores a session from a checkpoint\n",
    "        \n",
    "        :param sess: current session instance\n",
    "        :param model_path: path to file system checkpoint location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        logging.info(\"Model restored from file: %s\" % model_path)\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Trains a unet instance\n",
    "    \n",
    "    :param net: the unet instance to train\n",
    "    :param batch_size: size of training batch\n",
    "    :param optimizer: (optional) name of the optimizer to use (momentum or adam)\n",
    "    :param opt_kwargs: (optional) kwargs passed to the learning rate (momentum opt) and to the optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_path = \"prediction\"\n",
    "    verification_batch_size = 4\n",
    "    \n",
    "    def __init__(self, net, batch_size=1, optimizer=\"momentum\", num_gpus=1, opt_kwargs={}):\n",
    "        self.net = net\n",
    "        self.batch_size = batch_size\n",
    "        self.num_gpus = num_gpus\n",
    "        self.optimizer = optimizer\n",
    "        self.opt_kwargs = opt_kwargs\n",
    "        \n",
    "    def _get_optimizer(self, training_iters, global_step):\n",
    "        if self.optimizer == \"momentum\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.2)\n",
    "            decay_rate = self.opt_kwargs.pop(\"decay_rate\", 0.95)\n",
    "            \n",
    "            self.learning_rate_node = tf.train.exponential_decay(learning_rate=learning_rate, \n",
    "                                                        global_step=global_step, \n",
    "                                                        decay_steps=training_iters,  \n",
    "                                                        decay_rate=decay_rate, \n",
    "                                                        staircase=True)\n",
    "            \n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate_node, \n",
    "                                                   **self.opt_kwargs).minimize(self.net.cost, \n",
    "                                                                                global_step=global_step)\n",
    "        elif self.optimizer == \"adam\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.001)\n",
    "            self.learning_rate_node = tf.Variable(learning_rate)\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate_node, \n",
    "                                               **self.opt_kwargs).minimize(self.net.cost,\n",
    "                                                                     global_step=global_step)\n",
    "        \n",
    "        return optimizer\n",
    "        \n",
    "    def _initialize(self, training_iters, output_path, restore):\n",
    "        global_step = tf.Variable(0)\n",
    "        \n",
    "        self.norm_gradients_node = tf.Variable(tf.constant(0.0, shape=[len(self.net.gradients_node)]))\n",
    "        \n",
    "        if self.net.summaries:\n",
    "            tf.summary.histogram('norm_grads', self.norm_gradients_node)\n",
    "\n",
    "        tf.summary.scalar('loss', self.net.cost)\n",
    "        tf.summary.scalar('cross_entropy', self.net.cross_entropy)\n",
    "        tf.summary.scalar('accuracy', self.net.accuracy)\n",
    "\n",
    "        self.optimizer = self._get_optimizer(training_iters, global_step)\n",
    "        tf.summary.scalar('learning_rate', self.learning_rate_node)\n",
    "\n",
    "        self.summary_op = tf.summary.merge_all()        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        prediction_path = os.path.abspath(self.prediction_path)\n",
    "        output_path = os.path.abspath(output_path)\n",
    "        \n",
    "        if not restore:\n",
    "            logging.info(\"Removing '{:}'\".format(prediction_path))\n",
    "            shutil.rmtree(prediction_path, ignore_errors=True)\n",
    "            logging.info(\"Removing '{:}'\".format(output_path))\n",
    "            shutil.rmtree(output_path, ignore_errors=True)\n",
    "        \n",
    "        if not os.path.exists(prediction_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(prediction_path))\n",
    "            os.makedirs(prediction_path)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(output_path))\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        return init\n",
    "\n",
    "    def train(self, data_provider, output_path, training_iters=10, epochs=100, dropout=0.75, display_step=1, restore=False):\n",
    "        \"\"\"\n",
    "        Lauches the training process\n",
    "        \n",
    "        :param data_provider: callable returning training and verification data\n",
    "        :param output_path: path where to store checkpoints\n",
    "        :param training_iters: number of training mini batch iteration\n",
    "        :param epochs: number of epochs\n",
    "        :param dropout: dropout probability\n",
    "        :param display_step: number of steps till outputting stats\n",
    "        :param restore: Flag if previous model should be restored \n",
    "        \"\"\"\n",
    "        save_path = os.path.join(output_path, \"model.cpkt\")\n",
    "        if epochs == 0:\n",
    "            return save_path\n",
    "        \n",
    "        init = self._initialize(training_iters, output_path, restore)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            \n",
    "            if restore:\n",
    "                ckpt = tf.train.get_checkpoint_state(output_path)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.net.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            test_x, test_y = data_provider(self.verification_batch_size)\n",
    "            pred_shape = self.store_prediction(sess, test_x, test_y, \"_init\")\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter(output_path, graph=sess.graph)\n",
    "            logging.info(\"Start optimization\")\n",
    "            \n",
    "            avg_gradients = None\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0\n",
    "                for step in range((epoch*training_iters), ((epoch+1)*training_iters)):\n",
    "                    for i in range(self.num_gpus):\n",
    "                        with tf.device('/gpu:%d'i):\n",
    "                            with tf.name_scope('gpu_%d'%i):\n",
    "                                batch_x, batch_y = data_provider(self.batch_size) \n",
    "                                # Run optimization op (backprop)\n",
    "                                _, loss, lr, gradients = sess.run((self.optimizer, self.net.cost, self.learning_rate_node, self.net.gradients_node), \n",
    "                                                                  feed_dict={self.net.x: batch_x,\n",
    "                                                                             self.net.y: crop_to_shape(batch_y, pred_shape),\n",
    "                                                                             self.net.keep_prob: dropout})\n",
    "\n",
    "                                if avg_gradients is None:\n",
    "                                    avg_gradients = [np.zeros_like(gradient) for gradient in gradients]\n",
    "                                for i in range(len(gradients)):\n",
    "                                    avg_gradients[i] = (avg_gradients[i] * (1.0 - (1.0 / (step+1)))) + (gradients[i] / (step+1))\n",
    "\n",
    "                                norm_gradients = [np.linalg.norm(gradient) for gradient in avg_gradients]\n",
    "                                self.norm_gradients_node.assign(norm_gradients).eval()\n",
    "                                with tf.device('/cpu:0'):\n",
    "                                    if step % display_step == 0:\n",
    "                                        self.output_minibatch_stats(sess, summary_writer, step, batch_x, crop_to_shape(batch_y, pred_shape))\n",
    "\n",
    "                                total_loss += loss\n",
    "\n",
    "#                 print(\"epoch stats\")\n",
    "                self.output_epoch_stats(epoch, total_loss, training_iters, lr)\n",
    "#                 print(\"store predictions\")\n",
    "                self.store_prediction(sess, test_x, test_y, \"epoch_%s\"%epoch)\n",
    "                    \n",
    "                save_path = self.net.save(sess, save_path)\n",
    "            logging.info(\"Optimization Finished!\")\n",
    "            \n",
    "            return save_path\n",
    "        \n",
    "    def store_prediction(self, sess, batch_x, batch_y, name):\n",
    "#         logging.info(\"Storing prediction\")\n",
    "        prediction = sess.run(self.net.predicter, feed_dict={self.net.x: batch_x, \n",
    "                                                             self.net.y: batch_y, \n",
    "                                                             self.net.keep_prob: 1.})\n",
    "        pred_shape = prediction.shape\n",
    "        \n",
    "        loss = sess.run(self.net.cost, feed_dict={self.net.x: batch_x, \n",
    "                                                       self.net.y: crop_to_shape(batch_y, pred_shape), \n",
    "                                                       self.net.keep_prob: 1.})\n",
    "        \n",
    "        logging.info(\"Verification error= %.1f, loss= %.4f\" % (error_rate(prediction,crop_to_shape(batch_y, prediction.shape)),\n",
    "                                                               loss))\n",
    "              \n",
    "#         img = combine_img_prediction(batch_x, batch_y, prediction)\n",
    "#         save_image(img, \"%s/%s.jpg\"%(self.prediction_path, name))\n",
    "        \n",
    "        return pred_shape\n",
    "    \n",
    "    def output_epoch_stats(self, epoch, total_loss, training_iters, lr):\n",
    "        logging.info(\"Epoch {:}, Average loss: {:.4f}, learning rate: {:.4f}\".format(epoch, (total_loss / training_iters), lr))\n",
    "    \n",
    "    def output_minibatch_stats(self, sess, summary_writer, step, batch_x, batch_y):\n",
    "        # Calculate batch loss and accuracy\n",
    "#         logging.info(batch_x.shape)\n",
    "        summary_str, loss, acc, predictions = sess.run([self.summary_op, \n",
    "                                                            self.net.cost, \n",
    "                                                            self.net.accuracy, \n",
    "                                                            self.net.predicter], \n",
    "                                                           feed_dict={self.net.x: batch_x,\n",
    "                                                                      self.net.y: batch_y,\n",
    "                                                                      self.net.keep_prob: 1.})\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "        summary_writer.flush()\n",
    "        logging.info(\"Iter {:}, Minibatch Loss= {:.4f}, Training Accuracy= {:.4f}, Minibatch error= {:.1f}%\".format(step,\n",
    "                                                                                                            loss,\n",
    "                                                                                                            acc,\n",
    "                                                                                                            error_rate(predictions, batch_y)))\n",
    "\n",
    "\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return the error rate based on dense predictions and 1-hot labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    return 100.0 - (\n",
    "        100.0 *\n",
    "        np.sum(np.argmax(predictions, 4) == np.argmax(labels, 4)) /\n",
    "        (predictions.shape[0]*predictions.shape[1]*predictions.shape[2]*predictions.shape[3]))\n",
    "\n",
    "\n",
    "def get_image_summary(img, idx=0):\n",
    "    \"\"\"\n",
    "    Make an image summary for 5d tensor image with index idx\n",
    "    \"\"\"\n",
    "    \n",
    "    V = tf.slice(img, (0, 0, 0, 0, idx), (1, -1, -1, -1, 1))\n",
    "    V -= tf.reduce_min(V)\n",
    "    V /= tf.reduce_max(V)\n",
    "    V *= 255\n",
    "    \n",
    "    img_w = tf.shape(img)[1]\n",
    "    img_h = tf.shape(img)[2]\n",
    "    img_z = tf.shape(img)[3]\n",
    "    V = tf.reshape(V, tf.stack((img_w, img_h, img_z, 1)))\n",
    "    V = tf.transpose(V, (3, 0, 1, 2))\n",
    "    V = tf.reshape(V, tf.stack((-1, img_w, img_h, img_z, 1)))\n",
    "    return V\n",
    "\n",
    "def loadCases(p):\n",
    "    f = open(p)\n",
    "    res = []\n",
    "    for l in f:\n",
    "        l = l[:-1]\n",
    "        if l == \"\":\n",
    "            break\n",
    "        if l[-1] == '\\r':\n",
    "            l = l[:-1]\n",
    "        res.append(l)\n",
    "    return res\n",
    "\n",
    "class BaseDataProvider(object):\n",
    "    \"\"\"\n",
    "    Abstract base class for DataProvider implementation. Subclasses have to\n",
    "    overwrite the `_next_data` method that load the next data and label array.\n",
    "    This implementation automatically clips the data with the given min/max and\n",
    "    normalizes the values to (0,1]. To change this behavoir the `_process_data`\n",
    "    method can be overwritten. To enable some post processing such as data\n",
    "    augmentation the `_post_process` method can be overwritten.\n",
    "    :param a_min: (optional) min value used for clipping\n",
    "    :param a_max: (optional) max value used for clipping\n",
    "    \"\"\"\n",
    "    \n",
    "    channels = 1\n",
    "    n_class = 2\n",
    "    \n",
    "\n",
    "    def __init__(self, a_min=None, a_max=None):\n",
    "        self.a_min = a_min if a_min is not None else -np.inf\n",
    "        self.a_max = a_max if a_min is not None else np.inf\n",
    "\n",
    "    def _load_data_and_label(self, n=1):\n",
    "        train_data, labels = [], []\n",
    "        for i in range(n):\n",
    "            data, label = self._next_data()\n",
    "\n",
    "            train_data_ = self._process_data(data)\n",
    "            labels_ = self._process_labels(label)\n",
    "\n",
    "            train_data_, labels_ = self._post_process(train_data_, labels_)\n",
    "            train_data.append(train_data_)\n",
    "            labels.append(labels_)\n",
    "\n",
    "            nx = data.shape[0]\n",
    "            ny = data.shape[1]\n",
    "            nz = data.shape[2]\n",
    "\n",
    "        return np.array(train_data).reshape(n, nx, ny, nz, self.channels), np.array(labels).reshape(n, nx, ny, nz, self.n_class),\n",
    "    \n",
    "    def _process_labels(self, label):\n",
    "        if self.n_class == 2:\n",
    "            nx = label.shape[0]\n",
    "            ny = label.shape[1]\n",
    "            nz = label.shape[2]\n",
    "            labels = np.zeros((nx, ny, nz, self.n_class), dtype=np.float32)\n",
    "            labels[..., 1] = label\n",
    "            labels[..., 0] = ~label\n",
    "            return labels\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def _process_data(self, data):\n",
    "        # normalization\n",
    "        data = np.clip(np.fabs(data), self.a_min, self.a_max)\n",
    "        data -= np.amin(data)\n",
    "        data /= np.amax(data)\n",
    "        return data\n",
    "    \n",
    "    def _post_process(self, data, labels):\n",
    "        \"\"\"\n",
    "        Post processing hook that can be used for data augmentation\n",
    "        \n",
    "        :param data: the data array\n",
    "        :param labels: the label array\n",
    "        \"\"\"\n",
    "        return data, labels\n",
    "    \n",
    "    def __call__(self, n=1):\n",
    "        train_data, labels = self._load_data_and_label(n)\n",
    "        return train_data, labels\n",
    "    \n",
    "\n",
    "\n",
    "class ImageDataProvider(BaseDataProvider):\n",
    "    \"\"\"\n",
    "    Generic data provider for images, supports gray scale and colored images.\n",
    "    Assumes that the data images and label images are stored in the same folder\n",
    "    and that the labels have a different file suffix \n",
    "    e.g. 'train/fish_1.tif' and 'train/fish_1_mask.tif'\n",
    "    Usage:\n",
    "    data_provider = ImageDataProvider(\"..fishes/train/*.tif\")\n",
    "        \n",
    "    :param search_path: a glob search pattern to find all data and label images\n",
    "    :param a_min: (optional) min value used for clipping\n",
    "    :param a_max: (optional) max value used for clipping\n",
    "    :param data_suffix: suffix pattern for the data images. Default '.tif'\n",
    "    :param mask_suffix: suffix pattern for the label images. Default '_mask.tif'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_class = 2\n",
    "    \n",
    "    def __init__(self, search_path='', a_min=None, a_max=None, data_suffix=\".tif\", mask_suffix='_mask.tif'):\n",
    "        super(ImageDataProvider, self).__init__(a_min, a_max)\n",
    "        \n",
    "        self.file_idx = -1\n",
    "        \n",
    "        self.data_files = self._find_data_files()\n",
    "    \n",
    "        assert len(self.data_files) > 0, \"No training files\"\n",
    "        print(\"Number of files used: %s\" % len(self.data_files))\n",
    "        \n",
    "        img = self._load_file(self.data_files[0])\n",
    "        self.channels = 1 #if len(img.shape) == 2 else img.shape[-1]\n",
    "        \n",
    "        \n",
    "    def _find_data_files(self):\n",
    "        rootPath = \"/home/gp1514/Dropbox/2016-paolo/preprocessed_data/\"\n",
    "        dataPath = rootPath+\"LabelMaps_1.00-1.00-1.00/\"\n",
    "\n",
    "        trainCases = loadCases(\"train.txt\")\n",
    "        return [dataPath+name+'/case.nrrd' for name in trainCases]\n",
    "    \n",
    "    \n",
    "    def _load_file(self, path, dtype=np.float32):\n",
    "        tile = 148\n",
    "        zer = np.zeros((tile,tile,tile), dtype=dtype)\n",
    "        data = nrrd.read(path)[0].astype(dtype)\n",
    "        xmin = min(data.shape[0], tile)\n",
    "        ymin = min(data.shape[1], tile)\n",
    "        zmin = min(data.shape[2], tile)\n",
    "        zer[:xmin, :ymin, :zmin] = data[:xmin, :ymin, :zmin]\n",
    "        return zer\n",
    "\n",
    "    def _cycle_file(self):\n",
    "        self.file_idx += 1\n",
    "        if self.file_idx >= len(self.data_files):\n",
    "            self.file_idx = 0 \n",
    "        \n",
    "    def _next_data(self):\n",
    "        self._cycle_file()\n",
    "        image_name = self.data_files[self.file_idx]\n",
    "        label_name = image_name.replace('case', 'needles')\n",
    "\n",
    "             \n",
    "        img = self._load_file(image_name, np.float32)\n",
    "        label = self._load_file(label_name, np.bool)\n",
    "    \n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootPath = \"/home/gp1514/Dropbox/2016-paolo/preprocessed_data/\"\n",
    "dataPath = rootPath+\"LabelMaps_1.00-1.00-1.00/\"\n",
    "    \n",
    "nrrd.read(dataPath + '008/needles.nrrd')[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 18:27:40,381 Layers 4, features 32, filter size 3x3, pool size: 2x2\n",
      "2017-02-27 18:27:40,662 (?, ?, ?, ?, 2)\n",
      "2017-02-27 18:27:40,663 (?, ?, ?, ?, 2)\n",
      "2017-02-27 18:27:40,664 **************************************************\n",
      "2017-02-27 18:27:40,665 getting cost\n",
      "2017-02-27 18:27:40,665 (?, ?, ?, ?, 2)\n",
      "2017-02-27 18:27:40,666 (?, ?, ?, ?, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, ?, ?, ?) (?, ?, ?, ?, 128)\n",
      "(?, ?, ?, ?, ?) (?, ?, ?, ?, 64)\n",
      "(?, ?, ?, ?, ?) (?, ?, ?, ?, 32)\n"
     ]
    }
   ],
   "source": [
    "net = Unet(channels=1, \n",
    "                n_class=2, \n",
    "                layers=4, \n",
    "                features_root=32, summaries=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files used: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-27 18:27:41,615 Removing '/home/gp1514/Dropbox/Projects/unet/prediction'\n",
      "2017-02-27 18:27:41,616 Removing '/home/gp1514/Dropbox/Projects/unet/unet_trained'\n",
      "2017-02-27 18:27:41,617 Allocating '/home/gp1514/Dropbox/Projects/unet/prediction'\n",
      "2017-02-27 18:27:41,618 Allocating '/home/gp1514/Dropbox/Projects/unet/unet_trained'\n",
      "2017-02-27 18:27:45,907 Verification error= 90.9, loss= 1.0623\n",
      "2017-02-27 18:27:46,237 Start optimization\n",
      "2017-02-27 18:27:50,875 Iter 0, Minibatch Loss= 0.1865, Training Accuracy= 0.8972, Minibatch error= 10.3%\n",
      "2017-02-27 18:27:55,200 Iter 0, Minibatch Loss= 0.1509, Training Accuracy= 0.9460, Minibatch error= 5.4%\n",
      "2017-02-27 18:28:03,297 Iter 2, Minibatch Loss= 0.1009, Training Accuracy= 0.9976, Minibatch error= 0.2%\n",
      "2017-02-27 18:28:08,854 Iter 2, Minibatch Loss= 0.3749, Training Accuracy= 0.9978, Minibatch error= 0.2%\n",
      "2017-02-27 18:28:17,160 Iter 4, Minibatch Loss= 0.1359, Training Accuracy= 0.9999, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:22,392 Iter 4, Minibatch Loss= 0.0386, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:30,271 Iter 6, Minibatch Loss= 0.0189, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:35,708 Iter 6, Minibatch Loss= 0.0597, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:44,625 Iter 8, Minibatch Loss= 0.0078, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:49,975 Iter 8, Minibatch Loss= 0.0206, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:28:57,808 Iter 10, Minibatch Loss= 0.0073, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:03,193 Iter 10, Minibatch Loss= 0.0110, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:12,208 Iter 12, Minibatch Loss= 0.0058, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:17,401 Iter 12, Minibatch Loss= 0.0104, Training Accuracy= 0.9970, Minibatch error= 0.3%\n",
      "2017-02-27 18:29:26,420 Iter 14, Minibatch Loss= 0.0031, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:31,698 Iter 14, Minibatch Loss= 0.0143, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:40,498 Iter 16, Minibatch Loss= 0.0017, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:45,571 Iter 16, Minibatch Loss= 0.0161, Training Accuracy= 0.9877, Minibatch error= 1.2%\n",
      "2017-02-27 18:29:52,947 Iter 18, Minibatch Loss= 0.0013, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:29:57,499 Iter 18, Minibatch Loss= 0.0023, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:06,220 Iter 20, Minibatch Loss= 0.0038, Training Accuracy= 0.9968, Minibatch error= 0.3%\n",
      "2017-02-27 18:30:10,612 Iter 20, Minibatch Loss= 0.0043, Training Accuracy= 0.9976, Minibatch error= 0.2%\n",
      "2017-02-27 18:30:18,949 Iter 22, Minibatch Loss= 0.0009, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:23,962 Iter 22, Minibatch Loss= 0.0012, Training Accuracy= 0.9999, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:33,195 Iter 24, Minibatch Loss= 0.0008, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:37,233 Iter 24, Minibatch Loss= 0.0005, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:44,919 Iter 26, Minibatch Loss= 0.0005, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:50,390 Iter 26, Minibatch Loss= 0.0004, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:30:58,334 Iter 28, Minibatch Loss= 0.0003, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:03,080 Iter 28, Minibatch Loss= 0.0003, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:12,089 Iter 30, Minibatch Loss= 0.0002, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:17,704 Iter 30, Minibatch Loss= 0.0002, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:26,649 Iter 32, Minibatch Loss= 0.0003, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:32,207 Iter 32, Minibatch Loss= 0.0001, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:41,324 Iter 34, Minibatch Loss= 0.0001, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:46,706 Iter 34, Minibatch Loss= 0.0001, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:54,619 Iter 36, Minibatch Loss= 0.0007, Training Accuracy= 0.9996, Minibatch error= 0.0%\n",
      "2017-02-27 18:31:58,933 Iter 36, Minibatch Loss= 0.0001, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:02,181 Epoch 0, Average loss: 0.1179, learning rate: 0.1900\n",
      "2017-02-27 18:32:05,522 Verification error= 0.3, loss= 0.0034\n",
      "2017-02-27 18:32:11,096 Iter 38, Minibatch Loss= 0.0009, Training Accuracy= 0.9992, Minibatch error= 0.1%\n",
      "2017-02-27 18:32:16,551 Iter 38, Minibatch Loss= 0.0032, Training Accuracy= 0.9968, Minibatch error= 0.3%\n",
      "2017-02-27 18:32:25,518 Iter 40, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:30,356 Iter 40, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:39,330 Iter 42, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:45,131 Iter 42, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:54,086 Iter 44, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:32:58,588 Iter 44, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:07,372 Iter 46, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:11,786 Iter 46, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:20,820 Iter 48, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:26,141 Iter 48, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:34,945 Iter 50, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:40,800 Iter 50, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:49,119 Iter 52, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:33:54,408 Iter 52, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:02,560 Iter 54, Minibatch Loss= 0.0008, Training Accuracy= 0.9993, Minibatch error= 0.1%\n",
      "2017-02-27 18:34:07,150 Iter 54, Minibatch Loss= 0.0005, Training Accuracy= 0.9996, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:14,882 Iter 56, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:20,061 Iter 56, Minibatch Loss= 0.0008, Training Accuracy= 0.9992, Minibatch error= 0.1%\n",
      "2017-02-27 18:34:28,660 Iter 58, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:34,386 Iter 58, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:43,106 Iter 60, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:48,618 Iter 60, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:34:57,358 Iter 62, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:35:02,839 Iter 62, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:35:11,571 Iter 64, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:35:16,685 Iter 64, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:35:25,303 Iter 66, Minibatch Loss= 0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n",
      "2017-02-27 18:35:30,710 Iter 66, Minibatch Loss= -0.0000, Training Accuracy= 1.0000, Minibatch error= 0.0%\n"
     ]
    }
   ],
   "source": [
    "data_provider = ImageDataProvider()\n",
    "\n",
    "trainer = Trainer(net, optimizer=\"momentum\", opt_kwargs=dict(momentum=0.2), batch_size=1)\n",
    "path = trainer.train(data_provider, \"./unet_trained\", \n",
    "                     training_iters=38, \n",
    "                     epochs=100, \n",
    "                     dropout=0.5, \n",
    "                     display_step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = ImageDataProvider()\n",
    "img._load_data_and_label()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = net.predict(\"./unet_trained/model.cpkt\", img._load_data_and_label()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction[0].shape\n",
    "res = prediction[0][:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rres = np.where(res>0.73099)\n",
    "print(len(rres[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "xs,ys,zs = rres\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(xs, ys, zs, marker='o', alpha=0.3, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrrd.read(dataPath + '008/case.nrrd')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "200*78*1*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "160* 160* 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadCases('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.arange(9).reshape((3,3,1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = nrrd.read(dataPath + '008/needles.nrrd')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
