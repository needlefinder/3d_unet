{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fns import *\n",
    "from syntheticdata import synthetic_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2, summaries=True):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    \n",
    "    :param x: input tensor, shape [?,nx,ny,nz,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Layers: {layers}, FeaturesRoot: {features_root}, ConvolutionSize: {filter_size}*{filter_size}*{filter_size}, PoolingSize: {pool_size}*{pool_size}*{pool_size}\"\\\n",
    "                 .format(layers=layers, features_root=features_root, filter_size=filter_size, pool_size=pool_size))\n",
    "    \n",
    "    in_node = x\n",
    "    batch_size = tf.shape(x)[0] \n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "    in_size = 144\n",
    "    size = in_size\n",
    "\n",
    "   \n",
    "    # down layers\n",
    "    with tf.name_scope('going_down'):\n",
    "        for layer in range(0, layers):\n",
    "            with tf.name_scope('layer_down_%d'%layer):\n",
    "                features = 2**layer*features_root\n",
    "                stddev = 1 / (filter_size**3 * features)\n",
    "                if layer == 0:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, channels, features], stddev)\n",
    "                else:\n",
    "                    w1 = weight_variable([filter_size, filter_size, filter_size, features//2, features], stddev)\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features, features], stddev)\n",
    "                b1 = bias_variable([features])\n",
    "                b2 = bias_variable([features])\n",
    "                \n",
    "                conv1 = conv3d(in_node, w1, keep_prob)\n",
    "                tmp_h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(tmp_h_conv, w2, keep_prob)\n",
    "                dw_h_convs[layer] = tf.nn.elu(conv2 + b2)\n",
    "                \n",
    "                logging.info(\"Down Convoltion Layer: {layer} Size: {size}\".format(layer=layer,size=dw_h_convs[layer].get_shape()))\n",
    "                \n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size -= 4    \n",
    "                if layer < layers-1:\n",
    "                    pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "                    in_node = pools[layer]\n",
    "                    size /= 2    \n",
    "        \n",
    "    in_node = dw_h_convs[layers-1]\n",
    "        \n",
    "    # up layers\n",
    "    with tf.name_scope('going_up'):\n",
    "        for layer in range(layers-2, -1, -1):   \n",
    "            with tf.name_scope('layer_up_%d'%layer):\n",
    "                features = 2**(layer+1)*features_root\n",
    "                stddev = 1 / (filter_size**3 * features)\n",
    "\n",
    "                wd = weight_variable_devonc([pool_size, pool_size, pool_size, features//2, features], stddev)\n",
    "                bd = bias_variable([features//2])\n",
    "                h_deconv = tf.nn.elu(deconv3d(in_node, wd, pool_size) + bd)\n",
    "                h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)    \n",
    "                deconv[layer] = h_deconv_concat\n",
    "\n",
    "                w1 = weight_variable([filter_size, filter_size, filter_size, features, features//2], stddev)\n",
    "                w2 = weight_variable([filter_size, filter_size, filter_size, features//2, features//2], stddev)\n",
    "                b1 = bias_variable([features//2])\n",
    "                b2 = bias_variable([features//2])\n",
    "\n",
    "                conv1 = conv3d(h_deconv_concat, w1, keep_prob)\n",
    "                h_conv = tf.nn.elu(conv1 + b1)\n",
    "                conv2 = conv3d(h_conv, w2, keep_prob)\n",
    "                in_node = tf.nn.elu(conv2 + b2)\n",
    "                up_h_convs[layer] = in_node\n",
    "                \n",
    "                logging.info(\"Up Convoltion Layer: {layer} Size: {size}\".format(layer=layer,\n",
    "                                                                                size=tf.shape(dw_h_convs[layer])))\n",
    "                \n",
    "                weights.append((w1, w2))\n",
    "                biases.append((b1, b2))\n",
    "                convs.append((conv1, conv2))\n",
    "\n",
    "                size *= 2\n",
    "                size -= 4\n",
    "\n",
    "    # Output Map\n",
    "    with tf.name_scope('output_map'):\n",
    "        #stddev = 1 / (features_root)\n",
    "        weight = weight_variable([1, 1, 1, features_root, 1], stddev)\n",
    "        bias = bias_variable([1])\n",
    "        conv = conv3d(in_node, weight, tf.constant(1.0))\n",
    "        output_map = tf.nn.sigmoid(conv + bias)\n",
    "        up_h_convs[\"out\"] = output_map\n",
    "        logging.info(\"Output map shape {size}, offset {offset}\".format(size=output_map.get_shape(), offset=int(in_size-size)))\n",
    "\n",
    "        if summaries:\n",
    "#             for i, (c1, c2) in enumerate(convs):\n",
    "#                 tf.summary.image('summary_conv_%03d_01'%i, get_image_summary(c1))\n",
    "#                 tf.summary.image('summary_conv_%03d_02'%i, get_image_summary(c2))\n",
    "\n",
    "#             for k in pools.keys():\n",
    "#                 tf.summary.image('summary_pool_%03d'%k, get_image_summary(pools[k]))\n",
    "\n",
    "#             for k in deconv.keys():\n",
    "#                 tf.summary.image('summary_deconv_concat_%03d'%k, get_image_summary(deconv[k]))\n",
    "\n",
    "            for k in dw_h_convs.keys():\n",
    "                tf.summary.histogram(\"dw_convolution_%03d\"%k + '/activations', dw_h_convs[k])\n",
    "\n",
    "            for k in up_h_convs.keys():\n",
    "                tf.summary.histogram(\"up_convolution_%s\"%k + '/activations', up_h_convs[k])\n",
    "\n",
    "        variables = []\n",
    "        for w1,w2 in weights:\n",
    "            variables.append(w1)\n",
    "            variables.append(w2)\n",
    "\n",
    "        for b1,b2 in biases:\n",
    "            variables.append(b1)\n",
    "            variables.append(b2)\n",
    "        \n",
    "        variables.append(weight)\n",
    "        variables.append(bias)\n",
    "        \n",
    "    return output_map, variables, int(in_size - size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Unet(object):\n",
    "    \"\"\"\n",
    "    A unet implementation\n",
    "\n",
    "    :param channels: (optional) number of channels in the input image\n",
    "    :param n_class: (optional) number of output labels\n",
    "    :param cost: (optional) name of the cost function. Default is 'cross_entropy'\n",
    "    :param cost_kwargs: (optional) kwargs passed to the cost function. See Unet._get_cost for more options\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels=1, n_class=1, cost=\"dice_coefficient\", cost_kwargs={}, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.n_class = n_class\n",
    "        self.summaries = kwargs.get(\"summaries\", True)\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, None, None, None, channels], name='data')\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, None, None, None, n_class], name='target')\n",
    "        self.keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n",
    "\n",
    "        logits, self.variables, self.offset = create_conv_net(self.x, self.keep_prob, channels, n_class, **kwargs)\n",
    "        logging.info(\"Actual Output Shape: {}\".format(logits.get_shape()))\n",
    "        logging.info(\"Desired Output Shape: {}\".format(self.y.get_shape()))\n",
    "\n",
    "        self.logits = logits\n",
    "        self.predicter = self.logits\n",
    "        self.predicter_label = tf.cast(self.predicter >= 0.5, tf.float32)\n",
    "        self.correct_pred = tf.cast(\n",
    "            tf.equal(tf.reshape(self.predicter_label, [-1, n_class]), tf.reshape(self.y, [-1, n_class])), tf.float32)\n",
    "        self.cost = self._get_cost(self.logits, self.predicter, cost, cost_kwargs)\n",
    "        self.gradients_node = tf.gradients(self.cost, self.variables)\n",
    "        self.cross_entropy = tf.reduce_mean(\n",
    "            cross_entropy(tf.reshape(self.y, [-1, n_class], name='cross_entro_label_reshape'),\n",
    "                          tf.reshape(pixel_wise_softmax_2(logits), [-1, n_class], name='px_logit_reshape')))\n",
    "        self.accuracy = tf.reduce_mean(self.correct_pred)\n",
    "\n",
    "    def _get_cost(self, logits, predicter, cost_name, cost_kwargs):\n",
    "        \"\"\"\n",
    "        Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.\n",
    "        Optional arguments are:\n",
    "        class_weights: weights for the different classes in case of multi-class imbalance\n",
    "        regularizer: power of the L2 regularizers added to the loss function\n",
    "        \"\"\"\n",
    "        with tf.name_scope('cost_function'):\n",
    "            logging.info('*' * 50)\n",
    "            logging.info('getting cost')\n",
    "            logging.info(\"Logits: {}\".format(logits.get_shape()))\n",
    "            logging.info(\"Y: {}\".format(self.y.get_shape()))\n",
    "            flat_logits = tf.reshape(logits, [-1, self.n_class], name='flat_logits_reshape')\n",
    "            flat_predicter = tf.reshape(predicter, [-1, self.n_class], name='flat_predicter_reshape')\n",
    "            flat_labels = tf.reshape(self.y, [-1, self.n_class], name='flat_labels_reshape')\n",
    "            if cost_name == \"cross_entropy\":\n",
    "                class_weights = cost_kwargs.pop(\"class_weights\", None)\n",
    "\n",
    "                if class_weights is not None:\n",
    "                    class_weights = tf.constant(np.array(class_weights, dtype=np.float32))\n",
    "\n",
    "                    weight_map = tf.multiply(flat_labels, class_weights, name='weightmap')\n",
    "                    weight_map = tf.reduce_sum(weight_map, axis=1)\n",
    "\n",
    "                    loss_map = tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, labels=flat_labels)\n",
    "                    weighted_loss = tf.multiply(loss_map, weight_map, name='weightloss')\n",
    "\n",
    "                    loss = tf.reduce_mean(weighted_loss)\n",
    "\n",
    "                else:\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits,\n",
    "                                                                                  labels=flat_labels))\n",
    "            elif cost_name == \"dice_coefficient\":\n",
    "                intersection = tf.reduce_sum(flat_predicter * flat_labels)\n",
    "                union = tf.reduce_sum(flat_predicter) + tf.reduce_sum(flat_labels)\n",
    "                loss = 1 - 2 * intersection / union\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Unknown cost function: \" % cost_name)\n",
    "\n",
    "            regularizer = cost_kwargs.pop(\"regularizer\", None)\n",
    "            if regularizer is not None:\n",
    "                regularizers = sum([tf.nn.l2_loss(variable) for variable in self.variables])\n",
    "                loss += (regularizer * regularizers)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict(self, model_path, x_test):\n",
    "        \"\"\"\n",
    "        Uses the model to create a prediction for the given data\n",
    "\n",
    "        :param model_path: path to the model checkpoint to restore\n",
    "        :param x_test: Data to predict on. Shape [n, nx, ny, nz, channels]\n",
    "        :returns prediction: The unet prediction Shape [n, px, py, pz, labels] (px=nx-self.offset/2)\n",
    "        \"\"\"\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(init)\n",
    "\n",
    "            # Restore model weights from previously saved model\n",
    "            self.restore(sess, model_path)\n",
    "\n",
    "            y_dummy = np.empty((x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], self.n_class))\n",
    "            prediction = sess.run(self.predicter_label, feed_dict={self.x: x_test, self.y: y_dummy, self.keep_prob: 1.})\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def save(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Saves the current session to a checkpoint\n",
    "\n",
    "        :param sess: current session\n",
    "        :param model_path: path to file system location\n",
    "        \"\"\"\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "\n",
    "    def restore(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Restores a session from a checkpoint\n",
    "\n",
    "        :param sess: current session instance\n",
    "        :param model_path: path to file system checkpoint location\n",
    "        \"\"\"\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        logging.info(\"Model restored from file: %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_image_summary(img, idx=0):\n",
    "    \"\"\"\n",
    "    Make an image summary for 4d tensor image with index idx\n",
    "    \"\"\"\n",
    "    \n",
    "    V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
    "    V -= tf.reduce_min(V)\n",
    "    V /= tf.reduce_max(V)\n",
    "    V *= 255\n",
    "    \n",
    "    img_w = tf.shape(img)[1]\n",
    "    img_h = tf.shape(img)[2]\n",
    "    V = tf.reshape(V, tf.stack((img_w, img_h, 1)))\n",
    "    V = tf.transpose(V, (2, 0, 1))\n",
    "    V = tf.reshape(V, tf.stack((-1, img_w, img_h, 1)))\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Unet(channels=1, \n",
    "           n_class=1, \n",
    "           layers=4, \n",
    "           pool_size=2,\n",
    "           features_root=16, summaries=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data used: 37\n",
      "Number of validation data used: 7\n",
      "Number of testing data used: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e4ddae12f2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                      \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                      display_step=1)\n\u001b[0m",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_provider, output_path, training_array, validation_array, testing_array, training_iters, epochs, dropout, display_step, restore)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     _, loss, acc, lr, gradients, prediction_labels, y = sess.run((self.optimizer, self.net.cost,\n",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/dataprovider.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, array, datafile, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data_and_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_data_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data_and_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/dataprovider.py\u001b[0m in \u001b[0;36m_load_data_and_label\u001b[0;34m(self, datafile, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlabel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/dataprovider.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self, datafile)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# logging.info(\"Case: {}\".format(image_name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'case'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'needles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"noise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zero\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/dataprovider.py\u001b[0m in \u001b[0;36m_load_file\u001b[0;34m(self, path, dtype, padding)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_to_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/DATA/gp1514/Dropbox/Projects/pw25/ziyang/3d_unet/fns/functions.py\u001b[0m in \u001b[0;36mreshape_to_shape\u001b[0;34m(data, shape, padding)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTempshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zero\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTempshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_provider = ImageDataProvider(array=False)\n",
    "trainer = Trainer(net, batch_size=3, optimizer=\"adam\")\n",
    "path = trainer.train(data_provider, \n",
    "                     \"./unet_trained\",\n",
    "                     training_array = None,\n",
    "                     validation_array = None,\n",
    "                     testing_array = None,\n",
    "                     training_iters=37, \n",
    "                     epochs=50, \n",
    "                     dropout=0.75, \n",
    "                     display_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data used: 37\n",
      "Number of validation data used: 7\n",
      "Number of testing data used: 3\n"
     ]
    }
   ],
   "source": [
    "provider = ImageDataProvider()\n",
    "testing_data, label_data = provider._load_data_and_label(provider.testing_data_files,5)\n",
    "testing_data.shape\n",
    "# testing_data = provider._load_data_and_label(provider.training_data_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "prediction = net.predict(\"./unet_trained/model 44.cpkt\", testing_data[i][np.newaxis,...])[0][:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.unique(prediction, return_counts=True))\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "xs,ys,zs = np.where(prediction == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(xs+44, ys+44, zs+44, marker='o', alpha=0.3, s=5)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs,ys,zs = np.where(label_data[i, ...,0] == 1)\n",
    "ax.scatter(xs, ys, zs, marker='o',color='g', alpha=0.3, s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_data[1,...,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs,ys,zs = np.where(label_data[i, ...,0] == 1)\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(xs, ys, zs, marker='o', alpha=0.3, s=5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
