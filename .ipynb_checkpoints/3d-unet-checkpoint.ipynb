{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time, sys, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.flatten(y_true)\n",
    "    y_pred_f = tf.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def deconv3d(x, W, stride=1):\n",
    "    x_shape = tf.shape(x)\n",
    "    print(x.get_shape())\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] * 2, x_shape[4] // 2])\n",
    "    print(output_shape.get_shape())\n",
    "    print(W.get_shape())\n",
    "    return tf.nn.conv3d_transpose(x, W, output_shape, strides=[1, stride, stride, stride, 1], padding='VALID')\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "\n",
    "\n",
    "class LearningParameters:\n",
    "    learningRate = 0\n",
    "    lambda2 = 0\n",
    "    epochs = 0\n",
    "    batchSize = 0\n",
    "    doBatchNorm = 0\n",
    "    channels = 0\n",
    "    loss = 0\n",
    "    continueExp = 0\n",
    "    tile = 0\n",
    "    dropout = 0\n",
    "\n",
    "filter_size=3 \n",
    "\n",
    "def createUNet(x, filterNumStart, depth, lp):\n",
    "    # Placeholder for the input image\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    nx = tf.shape(x)[1]\n",
    "    ny = tf.shape(x)[2]\n",
    "    nz = tf.shape(x)[3]\n",
    "    x_image = tf.reshape(x, tf.stack([-1, nx, ny, nz, lp.channels]))\n",
    "    in_node = x_image\n",
    "\n",
    "    connections = []\n",
    "    filterNumStart = 8\n",
    "    '''\n",
    "    Going down\n",
    "    '''\n",
    "    for d in range(depth):\n",
    "        input_layer = tf.layers.batch_normalization(in_node)\n",
    "        # conv1\n",
    "        conv = tf.layers.conv3d(\n",
    "            inputs=input_layer,\n",
    "            filters=filterNumStart * 2 ** d,\n",
    "            kernel_size=[3, 3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        connections.append(conv)\n",
    "\n",
    "        conv = tf.layers.batch_normalization(conv)\n",
    "        # conv2\n",
    "        conv = tf.layers.conv3d(\n",
    "            inputs=conv,\n",
    "            filters=filterNumStart * 2 ** d * 2,\n",
    "            kernel_size=[3, 3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "\n",
    "        input_layer = tf.layers.batch_normalization(input_layer)\n",
    "\n",
    "        if d < depth - 1:\n",
    "            connections.append(conv)\n",
    "            # pool1\n",
    "            pool = tf.layers.max_pooling3d(\n",
    "                inputs=conv,\n",
    "                pool_size=[2, 2, 2],\n",
    "                strides=2)\n",
    "            input_layer = pool\n",
    "\n",
    "    '''\n",
    "    Going up\n",
    "    '''\n",
    "    ## start deconvoluion\n",
    "    for d in range(depth - 1):\n",
    "        features = 2**(depth-d+1)*4\n",
    "        stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "        \n",
    "        wd = weight_variable_devonc([2, 2, 2, features//2, features], stddev)\n",
    "        \n",
    "        deconv = deconv3d(conv, wd, filterNumStart * 2 ** (depth - d))\n",
    "        deconv = tf.layers.batch_normalization(deconv)\n",
    "        concat = tf.concat([connections[-1 - d], deconv])\n",
    "\n",
    "        conv = tf.layers.conv3d(\n",
    "            inputs=concat,\n",
    "            filters=filterNumStart * 2 ** d * 2,\n",
    "            kernel_size=[3, 3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "\n",
    "        conv = tf.layers.batch_normalization(conv)\n",
    "\n",
    "    network = tf.layers.conv3d(\n",
    "        inputs=conv,\n",
    "        filters=2,\n",
    "        kernel_size=[1, 1, 1],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    sh = network.get_shape()\n",
    "    return [network, network.get_shape()[2], (lp.tile - sh[2]) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainNet(train_fn, trainCases, path, savePath, e, lp, outdim, margin):\n",
    "    print(\"training....\")\n",
    "    totalSum = [0, 0, 0, 0, 0]\n",
    "    epochStartTime = time.clock()\n",
    "    index = 0\n",
    "    reportPath = savePath + \"report.txt\"\n",
    "    path2 = path + trainCases[0] + \"/\"\n",
    "    # lesions = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))[22:-22,22:-22,22:-22]\n",
    "    lesions = nrrd.read(path2 + \"needles.nrrd\")[0]\n",
    "    sh = lesions.shape\n",
    "    # fl = nib.load(path2+\"fl_unet_3d.nii.gz\").get_data()\n",
    "    # sh_fl = fl.shape\n",
    "    y = np.zeros((2, sh[0], sh[1], sh[2]), dtype='float32')\n",
    "    totalD = 0\n",
    "    featuresBatch = np.zeros(\n",
    "        (lp.batchSize, len(lp.channels), outdim + 2 * margin, outdim + 2 * margin, outdim + 2 * margin),\n",
    "        dtype='float32')\n",
    "    labelsBatch = np.zeros((lp.batchSize, 2, outdim, outdim, outdim), dtype='float32')\n",
    "\n",
    "    for c in trainCases:\n",
    "        caseStartTime = time.clock()\n",
    "        caseSum = [0, 0, 0, 0, 0]\n",
    "        featureImages = []\n",
    "        path2 = path + c + \"/\"\n",
    "        print(\"{t})loading images...\".format(t=index))\n",
    "        # y[1] = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))[22:-22,22:-22,22:-22]\n",
    "        y[1] = nrrd.read(path2 + \"needles.nrrd\")[0]\n",
    "        y[0] = np.ones_like(y[1]) - y[1]\n",
    "        if np.count_nonzero(y[1]) == 0:\n",
    "            print(\"skipping...\")\n",
    "            continue\n",
    "        for cc in lp.channels:\n",
    "            # featureImages.append(nib.load(path2+cc).get_data())\n",
    "            mri = nrrd.read(path2 + cc)[0]\n",
    "            mri = mri.astype(np.float32)\n",
    "            mri -= mri.min()\n",
    "            mri /= mri.max()\n",
    "            mri = np.pad(mri, 44, \"symmetric\")\n",
    "        featureImages.append(mri)\n",
    "\n",
    "        print(\"training....\")\n",
    "        mask = np.ones_like(featureImages[0])\n",
    "\n",
    "        caseD = 0\n",
    "        batchIndex = 0\n",
    "        coords = list(itertools.product(range(0, sh[0], outdim), range(0, sh[1], outdim), range(0, sh[2], outdim)))\n",
    "        numIter = len(coords)\n",
    "        shuffle(coords)\n",
    "        xlim = sh[0] - outdim\n",
    "        ylim = sh[1] - outdim\n",
    "        zlim = sh[2] - outdim\n",
    "        for coord in coords:\n",
    "            xx = min(coord[0], xlim)\n",
    "            yy = min(coord[1], ylim)\n",
    "            zz = min(coord[2], zlim)\n",
    "            labelsBatch[batchIndex, :, :, :, :] = y[:, xx:xx + outdim, yy:yy + outdim, zz:zz + outdim]\n",
    "            for ch in range(len(lp.channels)):\n",
    "                featuresBatch[batchIndex, ch, :, :, :] = featureImages[ch][xx:xx + outdim + 2 * margin,\n",
    "                                                         yy:yy + outdim + 2 * margin, zz:zz + outdim + 2 * margin]\n",
    "            batchIndex += 1\n",
    "            if batchIndex == lp.batchSize:\n",
    "                perf = train_fn(featuresBatch, labelsBatch)\n",
    "                caseD += perf[5] * perf[3]\n",
    "                totalD += perf[5] * perf[3]\n",
    "                caseSum = [sum(x) for x in zip(perf[:-1], caseSum)]\n",
    "                totalSum = [sum(x) for x in zip(perf[:-1], totalSum)]\n",
    "                print(\">>>\", e, c, coord, \":\", perf[0], perf[1], perf[2], perf[3], perf[4], perf[5])\n",
    "                batchIndex = 0\n",
    "\n",
    "        caseD = caseD / (caseSum[3] + 0.00001)\n",
    "        losses = [x * lp.batchSize / numIter for x in caseSum]\n",
    "        print(\"==========> patient time\", (time.clock() - caseStartTime) / 60.0, losses, caseD)\n",
    "        report = open(reportPath, \"a\")\n",
    "        report.write(str(c) + \",\" + str(losses[0]) + \",\" + str(losses[1]) + \",\" + str(losses[2]) + \",\" + str(\n",
    "            losses[3]) + \",\" + str(caseD) + \",\" + str(losses[4]) + \"\\n\")\n",
    "        report.close()\n",
    "        index += 1\n",
    "    totalD = totalD / (totalSum[3] + 0.00001)\n",
    "    losses = [x * lp.batchSize / (numIter * len(trainCases)) for x in totalSum]\n",
    "    print(\"epoch time\", (time.clock() - epochStartTime) / 60.0, losses, totalD)\n",
    "    report = open(reportPath, \"a\")\n",
    "    report.write(str(e) + \"train=====\" + str(losses[0]) + \",\" + str(losses[1]) + \",\" + str(losses[2]) + \",\" + str(\n",
    "        losses[3]) + \",\" + str(totalD) + \",\" + str(losses[4]) + \"\\n\")\n",
    "    report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validateNet(valid_fn, validCases, path, savePath, e, lp, outdim, margin):\n",
    "    print(\"validating....\")\n",
    "    totalSum = [0,0,0,0,0]\n",
    "    epochStartTime = time.clock()\n",
    "    index = 0\n",
    "    reportPath = savePath +\"report.txt\"\n",
    "    path2 = path + trainCases[0]+\"/\"\n",
    "    #lesions = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))[22:-22,22:-22,22:-22]\n",
    "    lesions = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))\n",
    "    sh = lesions.shape\n",
    "    #fl = nib.load(path2+\"fl_unet_3d.nii.gz\").get_data()\n",
    "    #sh_fl = fl.shape\n",
    "    y = np.zeros((2, sh[0], sh[1], sh[2]), dtype='float32')\n",
    "    totalD = 0\n",
    "    featuresBatch = np.zeros((lp.batchSize, len(lp.channels), outdim+2*margin, outdim+2*margin, outdim+2*margin), dtype='float32')\n",
    "    labelsBatch = np.zeros((lp.batchSize, 2, outdim, outdim, outdim), dtype='float32')\n",
    "\n",
    "    for c in validCases:\n",
    "        caseStartTime = time.clock()\n",
    "        caseSum = [0,0,0,0,0]\n",
    "        featureImages = []\n",
    "        path2 = path + c+\"/\"\n",
    "        print \"{t})loading images...\".format(t=index)\n",
    "        for cc in lp.channels:\n",
    "            #featureImages.append(nib.load(path2+cc).get_data())\n",
    "                        mri = sitk.GetArrayFromImage(sitk.ReadImage(path2+cc))\n",
    "                        mri = mri.astype(np.float32)\n",
    "                        mri -= mri.min()\n",
    "                        mri /= mri.max()\n",
    "                        mri = np.pad(mri, 44, \"symmetric\")\n",
    "                        featureImages.append(mri)\n",
    "                \n",
    "                #y[1] = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))[22:-22,22:-22,22:-22]\n",
    "                y[1] = sitk.GetArrayFromImage(sitk.ReadImage(path2+\"needles.nrrd\"))\n",
    "        y[0] = np.ones_like(y[1]) - y[1]\n",
    "                print \"validating....\"\n",
    "        mask = np.ones_like(featureImages[0])\n",
    "        \n",
    "        caseD = 0\n",
    "        batchIndex = 0\n",
    "        coords = list(itertools.product(range(0,sh[0]-sh[0]%outdim, outdim), range(0,sh[1]-sh[1]%outdim, outdim), range(0,sh[2]-sh[2]%outdim, outdim)))\n",
    "        numIter = len(coords)\n",
    "        shuffle(coords)\n",
    "        for coord in coords:\n",
    "            labelsBatch[batchIndex,:,:,:,:] = y[:, coord[0]:coord[0]+outdim, coord[1]:coord[1]+outdim, coord[2]:coord[2]+outdim]\n",
    "            for ch in range(len(lp.channels)):\n",
    "                featuresBatch[batchIndex,ch,:,:,:] = featureImages[ch][coord[0]:coord[0]+outdim+2*margin,coord[1]:coord[1]+outdim+2*margin,coord[2]:coord[2]+outdim+2*margin]\n",
    "            batchIndex += 1\n",
    "            if batchIndex == lp.batchSize:\n",
    "                perf = valid_fn(featuresBatch, labelsBatch)\n",
    "                caseD +=  perf[5]*perf[3]\n",
    "                totalD += perf[5]*perf[3]\n",
    "                caseSum = [sum(x) for x in zip(perf[:-1], caseSum)]\n",
    "                totalSum = [sum(x) for x in zip(perf[:-1], totalSum)]\n",
    "                print \">>>\", e, c, coord, \":\", perf[0], perf[1], perf[2], perf[3], perf[4], perf[5]\n",
    "                batchIndex=0\n",
    "\n",
    "        caseD = caseD/(caseSum[3]+0.00001)\n",
    "        losses=[x*lp.batchSize/numIter for x in caseSum]\n",
    "        print \"==========> patient time\",(time.clock()-caseStartTime)/60.0, losses, caseD\n",
    "        report = open(reportPath, \"a\")\n",
    "        report.write(str(c)+\",\"+str(losses[0])+\",\"+str(losses[1])+\",\"+str(losses[2])+\",\"+str(losses[3])+\",\"+str(caseD)+\",\"+str(losses[4])+\"\\n\")\n",
    "        report.close()\n",
    "        index +=1\n",
    "    totalD = totalD/(totalSum[3]+0.00001)\n",
    "    losses=[x*lp.batchSize/(numIter*len(trainCases)) for x in totalSum]\n",
    "    print \"epoch time\",(time.clock()-epochStartTime)/60.0, losses, totalD\n",
    "    report = open(reportPath, \"a\")\n",
    "    report.write(str(e)+\"validation=====\"+str(losses[0])+\",\"+str(losses[1])+\",\"+str(losses[2])+\",\"+str(losses[3])+\",\"+str(totalD)+\",\"+str(losses[4])+\"\\n\")\n",
    "    report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything begins...\n",
      "================================\n",
      "lr:0.0001\n",
      "epochs:250\n",
      "lambda2:4e-06\n",
      "batchSize:1\n",
      "channels:case.nrrd\n",
      "doBatchNorm:0\n",
      "loss:dice\n",
      "continue:0\n",
      "tile:148\n",
      "dropout:0.33\n",
      "(?, ?, ?, ?, 128)\n",
      "(5,)\n",
      "(2, 2, 2, 64, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(None), Dimension(None)]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-47d704e07498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-557dc24cb23a>\u001b[0m in \u001b[0;36mcreateUNet\u001b[0;34m(x, filterNumStart, depth, lp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mdeconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterNumStart\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mdeconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gp1514/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, training, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m       _scope=name)\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gp1514/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gp1514/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gp1514/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam_dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       raise ValueError('Input has undefined `axis` dimension. Input shape: ',\n\u001b[0;32m--> 118\u001b[0;31m                        input_shape)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(None), Dimension(None)]))"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"everything begins...\")\n",
    "rootPath = \"/home/gp1514/Dropbox/2016-paolo/preprocessed_data/\"\n",
    "dataPath = rootPath+\"LabelMaps_1.00-1.00-1.00/\"\n",
    "\n",
    "trainCases = loadCases(\"train.txt\")\n",
    "validCases = loadCases(\"valid.txt\")\n",
    "\n",
    "number = sys.argv[1]\n",
    "netPath = rootPath+\"networks/\"+number+\"/\"\n",
    "lp = loadLearningParameters(\"lp.txt\")\n",
    "\n",
    "# ftensor5 = T.TensorType('float32', (False,)*5)\n",
    "\n",
    "X = tf.zeros((1,1,1,1,1))\n",
    "Y = tf.zeros((1,1,1,1,1))\n",
    "\n",
    "[network, outdim, margin] = createUNet(X, 32, 4, lp)\n",
    "print(\"--\", margin, outdim)\n",
    "start = 0\n",
    "if lp.continueExp !=\"-\":\n",
    "    print(\"loading to continue from \",lp.continueExp)\n",
    "    network = load_parameters(network, netPath+lp.continueExp+\".npz\")\n",
    "    print(\"loaded! :)\")\n",
    "    start = int(lp.continueExp)+1\n",
    "\n",
    "weight = 0.000138 #findClassImbalance(trainCases, dataPath)\n",
    "print(\"++++++++++++++++++++++++++\", weight)\n",
    "print(\"creating train function...\")\n",
    "save_parameters(network, \"initial.npz\")\n",
    "valid_fn = loadValidFunction(X, Y, network, lp, weight)\n",
    "\n",
    "for e in range(start, lp.epochs):\n",
    "    print(\"===============================================now epoch\", e)\n",
    "    train_fn = loadTrainFunction(X, Y, network, lp, weight, e)\n",
    "    trainNet(train_fn, trainCases, dataPath, netPath, e, lp, outdim, margin)    \n",
    "    #validateNet(valid_fn, validCases, dataPath, netPath, e, lp, outdim, margin)\n",
    "    save_parameters(network, netPath+str(e)+\".npz\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_parameters(network, fname):\n",
    "    with np.load(fname) as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    #lasagne.layers.set_all_param_values(network, param_values)\n",
    "    return network\n",
    "\n",
    "\n",
    "def save_parameters(network, fname):\n",
    "    pass\n",
    "    #np.savez(fname, *lasagne.layers.get_all_param_values(network))\n",
    "\n",
    "\n",
    "def loadCases(p):\n",
    "    f = open(p)\n",
    "    res = []\n",
    "    for l in f:\n",
    "        l = l[:-1]\n",
    "        if l==\"\":\n",
    "            break\n",
    "        if l[-1]=='\\r':\n",
    "            l=l[:-1]\n",
    "        res.append(l)\n",
    "    return res\n",
    "\n",
    "\n",
    "def findClassImbalance(cases, path):\n",
    "    totalPos = 0\n",
    "    totalNeg = 0\n",
    "    total = 0\n",
    "\n",
    "    for c in cases:\n",
    "        path2 = path + c+\"/\"\n",
    "        lesions = nib.load(path2+\"dawmPos_unet_2d.nii.gz\").get_data()\n",
    "        mask = nib.load(path2+\"mask_unet_2d.nii.gz\").get_data()\n",
    "        pos = np.count_nonzero(lesions)\n",
    "        vox = np.count_nonzero(mask)\n",
    "        totalPos += pos\n",
    "        total += vox\n",
    "        print(\"Pos:\", pos,\"proportion:\", float(pos)/vox, \"totalProp:\", float(totalPos)/total)\n",
    "    return float(totalPos)/(total)\n",
    "\n",
    "\n",
    "def loadLearningParameters(path):\n",
    "    f = open(path)\n",
    "    lp = LearningParameters()\n",
    "    \n",
    "    with open(\"lp.txt\", 'r') as stream:\n",
    "        try:\n",
    "            par = (yaml.load(stream))\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    for k, v in par.items():\n",
    "        setattr(lp, k, v)\n",
    "    \n",
    "    print(\"================================\")\n",
    "    for k,v in par.items():\n",
    "        print(k + \":\"+ str(v))\n",
    "    \n",
    "    lp.channels=1\n",
    "\n",
    "    return lp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
